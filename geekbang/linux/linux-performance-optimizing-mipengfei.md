# 前言

性能指标：

- 应用负载
  - 吞吐
  - 延时
- 系统资源
  - 资源使用率
  - 饱和度



性能瓶颈的排查思路

0、有监控的情况下，首先去看看监控大盘，看看有没有异常报警，如果初期还没有监控的情况我会按照下面步骤去看看系统层面有没有异常
1、我首先会去看看系统的平均负载，使用top或者htop命令查看,平均负载体现的是系统的一个整体情况，他应该是cpu、内存、磁盘性能的一个综合，一般是平均负载的值大于机器cpu的核数，这时候说明机器资源已经紧张了
2、平均负载高了以后，接下来就要看看具体是什么资源导致，我首先会在top中看cpu每个核的使用情况，如果占比很高，那瓶颈应该是cpu,接下来就要看看是什么进程导致的
3、如果cpu没有问题，那接下来我会去看内存，首先是用free去查看内存的是用情况，但不直接看他剩余了多少，还要结合看看cache和buffer，然后再看看具体是什么进程占用了过高的内存，我也是是用top去排序
4、内存没有问题的话就要去看磁盘了，磁盘我用iostat去查看，我遇到的磁盘问题比较少
5、还有就是带宽问题，一般会用iftop去查看流量情况，看看流量是否超过的机器给定的带宽
6、涉及到具体应用的话，就要根据具体应用的设定参数来查看，比如连接数是否查过设定值等
7、如果系统层各个指标查下来都没有发现异常，那么就要考虑外部系统了，比如数据库、缓存、存储等

![img](https://static001.geekbang.org/resource/image/9e/7a/9ee6c1c5d88b0468af1a3280865a6b7a.png)

![img](https://static001.geekbang.org/resource/image/0f/ba/0faf56cd9521e665f739b03dd04470ba.png)

# CPU性能篇

## 2. 平均负载

```
root@chin:~# uptime 
17:33:39 up 578 days, 32 min,  1 user,  load average: 0.00, 0.08, 0.10
```

下面来看下每列的含义：

- 当前时间
- 系统运行时间
- 正在登陆用户数
- 过去 1 分钟、5 分钟、15 分钟的平均负载Load Average

**平均负载**是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。

- 可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。
- 不可中断状态的进程则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。**不可中断状态实际上是系统对进程和硬件设备的一种保护机制。**

所以平均负载其实就是平均活跃进程数。平均活跃进程数，直观上的理解就是单位时间内的活跃进程数，但它实际上是活跃进程数的指数衰减平均值。那么当平均负载为 2 时，意味着什么呢？

- 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用。
- 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲。
- 而在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU。



**合理的平均负载数**：

平均负载最理想的情况是等于 CPU 个数。

```
root@chin:~# grep 'model name' /proc/cpuinfo | wc -l
2
```

- 如果 1 分钟、5 分钟、15 分钟的三个值基本相同，或者相差不大，那就说明系统负载很平稳。
- 但如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去 15 分钟内却有很大的负载。
- 反过来，如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。一旦 1 分钟的平均负载接近或超过了 CPU 的个数，就意味着系统正在发生过载的问题，这时就得分析调查是哪里导致的问题，并要想办法优化了。

假设我们在一个单 CPU 系统上看到平均负载为 1.73，0.60，7.98，那么说明在过去 1 分钟内，系统有 73% 的超载，而在 15 分钟内，有 698% 的超载，从整体趋势来看，系统的负载在降低。

在生产环境中，当平均负载高于 CPU 数量 70% 的时候，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。



**CPU使用率**

平均负载不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待 I/O 的进程。 CPU 使用率，是单位时间内 CPU 繁忙情况的统计，跟平均负载并不一定完全对应。比如：

- CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的；
- I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高；
- 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。

**案列分析**：

环境准备：安装 stress 和 sysstat 包，如 apt install stress sysstat。

stress 是一个 Linux 系统压力测试工具，这里我们用作异常进程模拟平均负载升高的场景。而 sysstat 包含了常用的 Linux 性能工具，用来监控和分析系统的性能。我们的案例会用到这个包的两个命令 mpstat 和 pidstat。

- mpstat 是一个常用的多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。
- pidstat 是一个常用的进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。

此外，需要切换到root用户。

先来看下测试前的平均负载：

```
root@chin:~# uptime
17:48:08 up 578 days, 47 min,  2 users,  load average: 0.04, 0.07, 0.08
```

1. 场景1：CPU密集型进程

在第一个终端运行stress 命令，模拟一个 CPU 使用率 100% 的场景：

```
root@chin:~# stress --cpu 1 --timeout 600
stress: info: [9920] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd
```

第二个终端：

```shell
root@chin:~# watch -d uptime

Every 2.0s: uptime                                                                 Fri Nov 13 17:52:52 2020

 17:52:52 up 578 days, 51 min,  3 users,  load average: 0.97, 0.50, 0.25
```

在第三个终端运行 mpstat 查看 CPU 使用率的变化情况：

```shell
# -P ALL 表示监控所有CPU，后面数字5表示间隔5秒后输出一组数据
root@chin:~# mpstat -P ALL 5
Linux 4.4.0-142-generic (chin) 	11/13/2020 	_x86_64_	(2 CPU)

05:51:25 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
05:51:30 PM  all   52.76    0.00    2.01    0.00    0.00    0.00    0.00    0.00    0.00   45.23
05:51:30 PM    0  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
05:51:30 PM    1    5.05    0.00    4.04    0.00    0.00    0.00    0.00    0.00    0.00   90.91
```

从终端2中可以看出，1分钟的平均负载增加到了0.97，从终端三种可以看出正好有一个CPU的使用率为100%，但它的 iowait 只有 0。这说明，平均负载的升高正是由于 CPU 使用率为 100% 。

那么，到底是哪个进程导致了 CPU 使用率为 100% 呢？你可以使用 pidstat 来查询：

```shell
root@chin:~# pidstat -u 5 1
Linux 4.4.0-142-generic (chin) 	11/13/2020 	_x86_64_	(2 CPU)

05:55:04 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
05:55:09 PM   112      2841    0.00    0.20    0.00    0.20     1  mysqld
05:55:09 PM     0      6648    0.20    0.00    0.00    0.20     1  AliYunDunUpdate
05:55:09 PM     0      6684    0.20    0.20    0.00    0.40     1  AliYunDun
05:55:09 PM     0      9921  100.00    0.00    0.00  100.00     0  stress
```

从这里可以明显看到，stress 进程的 CPU 使用率为 100%。

2. 场景2：I/O密集型进程

首先还是运行 stress 命令，但这次模拟 I/O 压力，即不停地执行 sync：

```
root@chin:~# stress -i 1 --timeout 600
stress: info: [10684] dispatching hogs: 0 cpu, 1 io, 0 vm, 0 hdd
root@chin:~# sync
root@chin:~# sync
root@chin:~# sync
root@chin:~# sync
```

还是在第二个终端运行 uptime 查看平均负载的变化情况：

```
root@chin:~# watch -d uptime

Every 2.0s: uptime                                                                       Fri Nov 13 19:03:27 2020

 19:03:27 up 578 days,  2:02,  6 users,  load average: 1.28, 0.42, 0.22
```

然后，第三个终端运行 mpstat 查看 CPU 使用率的变化情况：

```shell
# 显示所有CPU的指标，并在间隔5秒输出一组数据
$ mpstat -P ALL 5 1
Linux 4.15.0 (ubuntu)     09/22/18     _x86_64_    (2 CPU)
13:41:28     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
13:41:33     all    0.21    0.00   12.07   32.67    0.00    0.21    0.00    0.00    0.00   54.84
13:41:33       0    0.43    0.00   23.87   67.53    0.00    0.43    0.00    0.00    0.00    7.74
13:41:33       1    0.00    0.00    0.81    0.20    0.00    0.00    0.00    0.00    0.00   98.99
```

从这里可以看到，1 分钟的平均负载会慢慢增加到 1.28，其中一个 CPU 的系统 CPU 使用率升高到了 23.87，而 iowait 高达 67.53%。这说明，平均负载的升高是由于 iowait 的升高。

那么到底是哪个进程，导致 iowait 这么高呢？我们还是用 pidstat 来查询：

```
root@chin:~# pidstat -u 5 1
Linux 4.4.0-142-generic (chin) 	11/13/2020 	_x86_64_	(2 CPU)

07:03:50 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command
07:03:55 PM     0      4801    0.00    0.20    0.00    0.20     0  AliSecGuard
07:03:55 PM     0      6684    0.80    0.40    0.00    1.20     0  AliYunDun
07:03:55 PM     0      9886    0.20    0.00    0.00    0.20     1  sshd
07:03:55 PM     0     16431    0.00   98.60    0.00   98.60     1  stress
```

可以发现，还是 stress 进程导致的。

3. 大量进程的场景

当系统中运行进程超出 CPU 运行能力时，就会出现等待 CPU 的进程。比如，我们还是使用 stress，但这次模拟的是 8 个进程：

```
$ stress -c 8 --timeout 600
```

由于系统只有 2 个 CPU，明显比 8 个进程要少得多，因而，系统的 CPU 处于严重过载状态，平均负载高达 7.97：

```
root@chin:~# uptime
 19:12:16 up 578 days,  2:11,  7 users,  load average: 7.90, 4.39, 1.97
```

接着再运行 pidstat 来看一下进程的情况：

```
# 间隔5秒后输出一组数据
$ pidstat -u 5 1
14:23:25      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
14:23:30        0      3190   25.00    0.00    0.00   74.80   25.00     0  stress
14:23:30        0      3191   25.00    0.00    0.00   75.20   25.00     0  stress
14:23:30        0      3192   25.00    0.00    0.00   74.80   25.00     1  stress
14:23:30        0      3193   25.00    0.00    0.00   75.00   25.00     1  stress
14:23:30        0      3194   24.80    0.00    0.00   74.60   24.80     0  stress
14:23:30        0      3195   24.80    0.00    0.00   75.00   24.80     0  stress
14:23:30        0      3196   24.80    0.00    0.00   74.60   24.80     1  stress
14:23:30        0      3197   24.80    0.00    0.00   74.80   24.80     1  stress
14:23:30        0      3200    0.00    0.20    0.00    0.20    0.20     0  pidstat
```

可以看出，8 个进程在争抢 2 个 CPU，每个进程等待 CPU 的时间（也就是代码块中的 %wait 列）高达 75%。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。

总结：

平均负载提供了一个快速查看系统整体性能的手段，反映了整体的负载情况。但只看平均负载本身，我们并不能直接发现，到底是哪里出现了瓶颈。所以，在理解平均负载时，也要注意：

- 平均负载高有可能是 CPU 密集型进程导致的；
- 平均负载高并不一定代表 CPU 使用率高，还有可能是 I/O 更繁忙了；
- 当发现负载高的时候，你可以使用 mpstat、pidstat 等工具，辅助分析负载的来源。





















