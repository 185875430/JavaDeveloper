[TOC]

# 前言

主要学习掌握jvm参数的调节。

# 1. JVM实用参数系列

JVM是Java Virtual Machine（Java虚拟机）的缩写，Java通过使用Java虚拟机屏蔽了与具体平台相关的信息，使得Java具备了一次编写，多处运行的特性。JVM一直是Java学习中的重点，也是难点。并发编程网组织翻译了JVM实用参数系列文章，旨在帮助大家了解JVM的结构以及相关参数。JVM实用参数系列一共包括八篇文章，由浅入深，从编译器、垃圾回收、内存调优等方面介绍JVM。

## 1.1 JVM实用参数（一）JVM类型以及编译器模式

现在的JVM运行Java程序（和其它的兼容性语言）时在高效性和稳定性方面做的非常出色。自适应内存管理、垃圾收集、即时编译、动态类加载、锁优化——这里仅仅列举了某些场景下会发生的神奇的事情，但他们几乎不会直接与普通的程序员相关。在运行时，JVM会不断的计算并优化应用或者应用的某些部分。

虽然有了这种程度的自动化（或者说有这么多自动化），但是JVM仍然提供了足够多的外部监控和手动调优工具。在有错误或低性能的情况下，JVM必须能够让专家调试。顺便说一句，除了这些隐藏在引擎中的神奇功能，允许大范围的手动调优也是现代JVM的优势之一。有趣的是，一些命令行参数可以在JVM启动时传入到JVM中。一些JVM提供了几百个这样的参数，所以如果没有这方面的知识很容易迷失。这系列博客的目标是着重讲解日常相关的一些参数以及他们的适用场合。我们将专注于Java6的Sun/Oracle HotSpot JVM，大多数情况下，这些参数也会适用于其他一些流行的JVM里。

**-server and -client**

有两种类型的 HotSpot JVM，即”server”和”client”。服务端的VM中的默认为堆提供了一个更大的空间以及一个并行的垃圾收集器，并且在运行时可以更大程度地优化代码。客户端的VM更加保守一些（校对注：这里作者指客户端虚拟机有较小的默认堆大小），这样可以缩短JVM的启动时间和占用更少的内存。有一个叫”JVM功效学”的概念，它会在JVM启动的时候根据可用的硬件和操作系统来自动的选择JVM的类型。[具体](http://docs.oracle.com/javase/6/docs/technotes/guides/vm/server-class.html)[的标准可以在这里找到](http://docs.oracle.com/javase/6/docs/technotes/guides/vm/server-class.html)。从标准表中，我们可以看到客户端的VM只在32位系统中可用。

如果我们不喜欢预选（校对注：指JVM自动选择的JVM类型）的JVM，我们可以使用-server和-client参数来设置使用服务端或客户端的VM。虽然当初服务端VM的目标是长时间运行的服务进程，但是现在看来，在运行独立应用程序时它比客户端VM有更出色的性能。当应用的性能非常重要时，我推荐使用-server参数来选择服务端VM。一个常见的问题：在一个32位的系统上，HotSpot JDK可以运行服务端VM，但是32位的JRE只能运行客户端VM。

**-version and -showversion**

当我们调用“java”命令时，我们如何才能知道我们安装的是哪个版本的Java和JVM类型呢？在同一个系统中安装多个Java，如果不注意的话有运行错误JVM的风险。在不同的Linux版本上预装JVM这方面，我承认现在已经变的比以前好很多了。幸运的是，我们现在可以使用-version参数，它可以打印出正在使用的JVM的信息。例如：

```shell
`$ java -version java version "1.6.0_24" Java(TM) SE Runtime Environment (build 1.6.0_24-b07) Java HotSpot(TM) Client VM (build 19.1-b02, mixed mode, sharing)`
```

输出显示的是Java版本号(1.6.0_24)和JRE确切的build号(1.6.0_24-b07)。我们也可以看到JVM的名字(HotSpot)、类型(client)和build ID（19.1-b02) ）。除此之外，我们还知道JVM以混合模式(mixed mode)在运行，这是HotSpot默认的运行模式，意味着JVM在运行时可以动态的把字节码编译为本地代码。我们也可以看到类数据共享（class data sharing）是开启的，类数据共享（class data sharing）是一种在只读缓存（在jsa文件中，”Java Shared Archive”）中存储JRE的系统类，被所有Java进程的类加载器用来当做共享资源。类数据共享(Class data sharing)可能在经常从jar文档中读所有的类数据的情况下显示出性能优势。

-version参数在打印完上述信息后立即终止JVM。还有一个类似的参数-showversion可以用来输出相同的信息，但是-showversion紧接着会处理并执行Java程序。因此，-showversion对几乎所有Java应用的命令行都是一个有效的补充。你永远不知道你什么时候，突然需要了解一个特定的Java应用（崩溃时）使用的JVM的一些信息。在启动时添加-showversion，我们就能保证当我们需要时可以得到这些信息。

**-Xint, -Xcomp, 和 -Xmixed**

-Xint和-Xcomp参数和我们的日常工作不是很相关，但是我非常有兴趣通过它来了解下JVM。在解释模式(interpreted mode)下，-Xint标记会强制JVM执行所有的字节码，当然这会降低运行速度，通常低10倍或更多。-Xcomp参数与它（-Xint）正好相反，JVM在第一次使用时会把所有的字节码编译成本地代码，从而带来最大程度的优化。这听起来不错，因为这完全绕开了缓慢的解释器。然而，很多应用在使用-Xcomp也会有一些性能损失，当然这比使用-Xint损失的少，原因是-xcomp没有让JVM启用JIT编译器的全部功能。JIT编译器在运行时创建方法使用文件，然后一步一步的优化每一个方法，有时候会主动的优化应用的行为。这些优化技术，比如，积极的分支预测（optimistic branch prediction），如果不先分析应用就不能有效的使用。另一方面方法只有证明它们与此相关时才会被编译，也就是，在应用中构建某种热点。被调用很少（甚至只有一次）的方法在解释模式下会继续执行，从而减少编译和优化成本。

注意混合模式也有他自己的参数，-Xmixed。最新版本的HotSpot的默认模式是混合模式，所以我们不需要特别指定这个标记。我们来用对象填充HashMap然后检索它的结果做一个简单的用例。每一个例子，它的运行时间都是很多次运行的平均时间。

```shell
`$ java -server -showversion Benchmark java version "1.6.0_24" Java(TM) SE Runtime Environment (build 1.6.0_24-b07) Java HotSpot(TM) Server VM (build 19.1-b02, mixed mode)   Average time: 0.856449 seconds`
```

当然也有很多使-Xcomp表现很好的例子。特别是运行时间长的应用，我强烈建议大家使用JVM的默认设置,让JIT编译器充分发挥其动态潜力，毕竟JIT编译器是组成JVM最重要的组件之一。事实上，正是因为JVM在这方面的进展才让Java不再那么慢。

## 1.2 JVM实用参数（二）参数分类和即时（JIT）编译器诊断

在这个系列的第二部分，我来介绍一下HotSpot JVM提供的不同类别的参数。我同样会讨论一些关于JIT编译器诊断的有趣参数。

**JVM 参数分类**

HotSpot JVM 提供了三类参数。

第一类包括了**标准**参数。顾名思义，标准参数中包括功能和输出的参数都是很稳定的，很可能在将来的JVM版本中不会改变。你可以用java命令（或者是用 java -help）检索出所有标准参数。我们在第一部分中已经见到过一些标准参数，例如：-server。

第二类是**X参数(稳定)**，非标准化的参数在将来的版本中可能会改变。所有的这类参数都以-X开始，并且可以用java -X来检索。注意，不能保证所有参数都可以被检索出来，其中就没有-Xcomp。

第三类是包含**XX参数（实验中）**（到目前为止最多的），它们同样不是标准的，甚至很长一段时间内不被列出来（最近，这种情况有改变 ，我们将在本系列的第三部分中讨论它们）。然而，在实际情况中X参数和XX参数并没有什么不同。X参数的功能是十分稳定的，然而很多XX参数仍在实验当中（主要是JVM的开发者用于debugging和调优JVM自身的实现）。值的一读的介绍非标准参数的文档 [HotSpot JVM documentation](http://www.oracle.com/technetwork/java/javase/tech/vmoptions-jsp-140102.html)，其中明确的指出XX参数不应该在不了解的情况下使用。这是真的，并且我认为这个建议同样适用于X参数（同样一些标准参数也是）。不管类别是什么，在使用参数之前应该先了解它可能产生的影响。![Read More...](data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7)

用一句话来说明XX参数的语法。所有的XX参数都以”-XX:”开始，但是随后的语法不同，取决于参数的类型。

- 对于布尔类型的参数，我们有”+”或”-“，然后才设置JVM选项的实际名称。例如，-XX:+<name>用于激活<name>选项，而-XX:-<name>用于注销选项。
- 对于需要非布尔值的参数，如string或者integer，我们先写参数的名称，后面加上”=”，最后赋值。例如，  -XX:<name>=<value>给<name>赋值<value>。

现在让我们来看看JIT编译方面的一些XX参数。

-XX:+PrintCompilation and -XX:+CITime

当一个Java应用运行时，非常容易查看JIT编译工作。通过设置-XX:+PrintCompilation，我们可以简单的输出一些关于从字节码转化成本地代码的编译过程。我们来看一个服务端VM运行的例子：

```shell
`$ java -server -XX:+PrintCompilation Benchmark   1       java.lang.String::hashCode (64 bytes)   2       java.lang.AbstractStringBuilder::stringSizeOfInt (21 bytes)   3       java.lang.Integer::getChars (131 bytes)   4       java.lang.Object::<init> (1 bytes) ---   n   java.lang.System::arraycopy (static)   5       java.util.HashMap::indexFor (6 bytes)   6       java.lang.Math::min (11 bytes)   7       java.lang.String::getChars (66 bytes)   8       java.lang.AbstractStringBuilder::append (60 bytes)   9       java.lang.String::<init> (72 bytes)  10       java.util.Arrays::copyOfRange (63 bytes)  11       java.lang.StringBuilder::append (8 bytes)  12       java.lang.AbstractStringBuilder::<init> (12 bytes)  13       java.lang.StringBuilder::toString (17 bytes)  14       java.lang.StringBuilder::<init> (18 bytes)  15       java.lang.StringBuilder::append (8 bytes) [...]  29       java.util.regex.Matcher::reset (83 bytes)`
```

每当一个方法被编译，就输出一行-XX:+PrintCompilation。每行都包含顺序号（唯一的编译任务ID）和已编译方法的名称和大小。因此，顺序号1，代表编译String类中的hashCode方法到原生代码的信息。根据方法的类型和编译任务打印额外的信息。例如，本地的包装方法前方会有”n”参数，像上面的System::arraycopy一样。注意这样的方法不会包含顺序号和方法占用的大小，因为它不需要编译为本地代码。同样可以看到被重复编译的方法，例如StringBuilder::append顺序号为11和15。输出在顺序号29时停止 ，这表明在这个Java应用运行时总共需要编译29个方法。

没有官方的文档关于-XX:+PrintCompilation，但是[这个](https://gist.github.com/rednaxelafx/1165804#file_notes.md)[描述](https://gist.github.com/rednaxelafx/1165804#file_notes.md)是对于此参数比较好的。我推荐更深入学习一下。

JIT编译器输出帮助我们理解客户端VM与服务端VM的一些区别。用服务端VM，我们的应用例子输出了29行，同样用客户端VM，我们会得到55行。这看起来可能很怪，因为服务端VM应该比客户端VM做了“更多”的编译。然而，由于它们各自的默认设置，服务端VM在判断方法是不是热点和需不需要编译时比客户端VM观察方法的时间更长。因此，在使用服务端VM时，一些潜在的方法会稍后编译就不奇怪了。

通过另外设置-XX:+CITime，我们可以在JVM关闭时得到各种编译的统计信息。让我们看一下一个特定部分的统计：

```java
`$ java -server -XX:+CITime Benchmark [...] Accumulated compiler times (for compiled methods only) ------------------------------------------------   Total compilation time   :  0.178 s     Standard compilation   :  0.129 s, Average : 0.004     On stack replacement   :  0.049 s, Average : 0.024 [...]`
```

总共用了0.178s（在29个编译任务上）。这些，”on stack replacement”占用了0.049s，即编译的方法目前在堆栈上用去的时间。这种技术并不是简单的实现性能显示，实际上它是非常重要的。没有”on stack replacement”，方法如果要执行很长时间（比如，它们包含了一个长时间运行的循环），它们运行时将不会被它们编译过的副本替换。

再一次，客户端VM与服务端VM的比较是非常有趣的。客户端VM相应的数据表明，即使有55个方法被编译了，但这些编译总共用了只有0.021s。服务端VM做的编译少但是用的时间却比客户端VM多。这个原因是，使用服务端VM在生成本地代码时执行了更多的优化。

在本系列的第一部分，我们已经学了-Xint和-Xcomp参数。结合使用-XX:+PrintCompilation和-XX:+CITime，在这两个情况下（校对者注，客户端VM与服务端VM），我们能对JIT编译器的行为有更好的了解。使用-Xint，-XX:+PrintCompilation在这两种情况下会产生0行输出。同样的，使用-XX:+CITime时，证实在编译上没有花费时间。现在换用-Xcomp，输出就完全不同了。在使用客户端VM时会产生726行输出，然后没有更多的，这是因为每个相关的方法都被编译了。使用服务端VM，我们甚至能得到993行输出，这告诉我们更积极的优化被执行了。同样，JVM 拆机(JVM teardown)时打印出的统计显示了两个VM的巨大不同。考虑服务端VM的运行：

```shell
`$ java -server -Xcomp -XX:+CITime Benchmark [...] Accumulated compiler times (for compiled methods only) ------------------------------------------------   Total compilation time   :  1.567 s     Standard compilation   :  1.567 s, Average : 0.002     On stack replacement   :  0.000 s, Average : -1.#IO [...]`
```

使用-Xcomp编译用了1.567s，这是使用默认设置（即，混合模式）的10倍。同样，应用程序的运行速度要比用混合模式的慢。相比较之下，客户端VM使用-Xcomp编译726个方法只用了0.208s，甚至低于使用-Xcomp的服务端VM。

补充一点，这里没有”on stack replacement”发生，因为每一个方法在第一次调用时被编译了。损坏的输出“Average: -1.#IO”（正确的是:0）再一次表明了，非标准化的输出参数不是非常可靠。

-XX:+UnlockExperimentalVMOptions

有些时候当设置一个特定的JVM参数时，JVM会在输出“Unrecognized VM option”后终止。如果发生了这种情况，你应该首先检查你是否输错了参数。然而，如果参数输入是正确的，并且JVM并不识别，你或许需要设置-XX:+UnlockExperimentalVMOptions 来解锁参数。我不是非常清楚这个安全机制的作用，但我猜想这个参数如果不正确使用可能会对JVM的稳定性有影响（例如，他们可能会过多的写入debug输出的一些日志文件）。

有一些参数只是在JVM开发时用，并不实际用于Java应用。如果一个参数不能被 -XX:+UnlockExperimentalVMOptions 开启，但是你真的需要使用它，此时你可以尝试使用debug版本的JVM。对于Java 6 HotSpot JVM你可以从[这里找到](https://jdk6.java.net/download.html)。

-XX:+LogCompilation and -XX:+PrintOptoAssembly

如果你在一个场景中发现使用 -XX:+PrintCompilation，不能够给你足够详细的信息，你可以使用 -XX:+LogCompilation把扩展的编译输出写到“hotspot.log”文件中。除了编译方法的很多细节之外，你也可以看到编译器线程启动的任务。注意-XX:+LogCompilation 需要使用-XX:+UnlockExperimentalVMOptions来解锁。

JVM甚至允许我们看到从字节码编译生成到本地代码。使用-XX:+PrintOptoAssembly，由编译器线程生成的本地代码被输出并写到“hotspot.log”文件中。使用这个参数要求运行的服务端VM是debug版本。我们可以研究-XX:+PrintOptoAssembly的输出，以至于了解JVM实际执行什么样的优化，例如，关于死代码的消除。一个非常有趣的文章提供了一个[例子](https://weblogs.java.net/blog/2008/03/30/deep-dive-assembly-code-java)。

## 1.3 JVM实用参数（三）打印所有XX参数及值

本篇文章基于Java 6（update 21oder 21之后）版本， HotSpot JVM 提供给了两个新的参数，在JVM启动后，在命令行中可以输出所有XX参数和值。

```
-XX:+PrintFlagsFinal and -XX:+PrintFlagsInitial
```

让我们现在就了解一下新参数的输出。以 -client 作为参数的 -XX:+`PrintFlagsFinal`   的结果是一个按字母排序的590个参数表格（注意，每个release版本参数的数量会不一样。

```shell
$ java -client -XX:+PrintFlagsFinal Benchmark
[Global flags]
uintx AdaptivePermSizeWeight               = 20               {product}
uintx AdaptiveSizeDecrementScaleFactor     = 4                {product}
uintx AdaptiveSizeMajorGCDecayTimeScale    = 10               {product}
uintx AdaptiveSizePausePolicy              = 0                {product}[...]
uintx YoungGenerationSizeSupplementDecay   = 8                {product}
uintx YoungPLABSize                        = 4096             {product}
 bool ZeroTLAB                             = false            {product}
 intx hashCode                             = 0                {product}
```

*(校对注：你可以尝试在命令行输入上面的命令，亲自实现下)*

表格的每一行包括五列，来表示一个XX参数。第一列表示参数的数据类型，第二列是名称，第四列为值，第五列是参数的类别。第三列”=”表示第四列是参数的默认值，而”:=” 表明了参数被用户或者JVM赋值了。

注意对于这个例子我只是用了Benchmark类，因为这个系列前面的章节也是用的这个类。甚至没有一个主类的情况下你能得到相同的输出，通过运行java 带另外的参数 -version.现在让我们检查下 server VM提供了多少个参数。我们也能指定参数`-XX:+UnlockExperimentalVMOptions` 和`-XX:+UnlockDiagnosticVMOptions ；来解锁任何额外的隐藏参数。`

```
$ java -server -XX:+UnlockExperimentalVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal Benchmark
```

724个参数，让我们看一眼那些已经被赋值的参数。

```
$ java -server -XX:+UnlockExperimentalVMOptions -XX:+UnlockDiagnosticVMOptions -XX:+PrintFlagsFinal Benchmark | grep ":"
uintx InitialHeapSize                     := 57505088         {product}
uintx MaxHeapSize                         := 920649728        {product}
uintx ParallelGCThreads                   := 4                {product}
 bool PrintFlagsFinal                     := true             {product}
 bool UseParallelGC                       := true             {product}
```

（校对注：这个命令非常有用）我们仅设置一个自己的参数 -XX:+PrintFlagsFinal。其他参数通过server VM基于系统设置的，以便以合适的堆大小和GC设置运行。

如果我们只想看下所有XX参数的默认值，能够用一个相关的参数，-XX:+PrintFlagsInitial  。 用 `-XX:+PrintFlagsInitial`, 只是展示了第三列为“=”的数据（也包括那些被设置其他值的参数）。

然而，注意当与-XX:+PrintFlagsFinal 对比的时候，一些参数会丢失，大概因为这些参数是动态创建的。

研究表格的内容是很有意思的，通过比较client和server VM的行为，很明显了解哪些参数会影响其他的参数。有兴趣的读者，可以看一下这篇不错文章[Inspecting HotSpot JVM Options](http://q-redux.blogspot.com/2011/01/inspecting-hotspot-jvm-options.html)。这个文章主要解释了第五列的参数类别。

**-XX:+PrintCommandLineFlags**

让我们看下另外一个参数，事实上这个参数非常有用: `-XX:+PrintCommandLineFlags`。这个参数让JVM打印出那些已经被用户或者JVM设置过的详细的XX参数的名称和值。

换句话说，它列举出 `-XX:+PrintFlagsFinal的结果中第三列有":="的参数。以这种方式，`我们可以用-XX:+PrintCommandLineFlags作为快捷方式来查看修改过的参数。看下面的例子。

```
$ java -server -XX:+PrintCommandLineFlags Benchmark 
 -XX:InitialHeapSize=57505088 -XX:MaxHeapSize=920081408 -XX:ParallelGCThreads=4 -XX:+PrintCommandLineFlags -XX:+UseParallelGC
```

现在如果我们每次启动java 程序的时候设置 -XX:+PrintCommandLineFlags 并且输出到日志文件上，这样会记录下我们设置的JVM 参数对应用程序性能的影响。类似于 -showversion(见 Part1)，我建议 –XX:+PrintCommandLineFlags 这个参数应该总是设置在JVM启动的配置项里。因为你从不知道你什么时候会需要这些信息。

## 1.4 JVM实用参数（四）内存调优

理想的情况下，一个Java程序使用JVM的默认设置也可以运行得很好，所以一般来说，没有必要设置任何JVM参数。然而，由于一些性能问题（很不幸的是，这些问题经常出现），一些相关的JVM参数知识会是我们工作中得好伙伴。在这篇文章中，我们将介绍一些关于JVM内存管理的参数。知道并理解这些参数，将对开发者和运维人员很有帮助。

所有已制定的HotSpot内存管理和垃圾回收算法都基于一个相同的堆内存划分：新生代（young generation）里存储着新分配的和较年轻的对象，老年代（old generation）里存储着长寿的对象。在此之外，永久代（permanent generation）存储着那些需要伴随整个JVM生命周期的对象，比如，已加载的对象的类定义或者String对象内部Cache。接下来，我们将假设堆内存是按照新生代、老年代和永久代这一经典策略划分的。然而，其他的一些堆内存划分策略也是可行的，一个突出的例子就是新的G1垃圾回收器，它模糊了新生代和老年代之间的区别。此外，目前的开发进程似乎表明在未来的HotSpot JVM版本中，将不会区分老年代和永久代。

**-Xms and -Xmx (or: -XX:InitialHeapSize and -XX:MaxHeapSize)**

-Xms和-Xmx可以说是最流行的JVM参数，它们可以允许我们指定JVM的初始和最大堆内存大小。一般来说，这两个参数的数值单位是Byte，但同时它们也支持使用速记符号，比如“k”或者“K”代表“kilo”，“m”或者“M”代表“mega”，“g”或者“G”代表“giga”。举个例子，下面的命令启动了一个初始化堆内存为128M，最大堆内存为2G，名叫“MyApp”的Java应用程序。

| `1`  | `java -Xms128m -Xmx2g MyApp` |
| ---- | ---------------------------- |
|      |                              |

在实际使用过程中，初始化堆内存的大小通常被视为堆内存大小的下界。然而JVM可以在运行时动态的调整堆内存的大小，所以理论上来说我们有可能会看到堆内存的大小小于初始化堆内存的大小。但是即使在非常低的堆内存使用下，我也从来没有遇到过这种情况。这种行为将会方便开发者和系统管理员，因为我们可以通过将“-Xms”和“-Xmx”设置为相同大小来获得一个固定大小的堆内存。 -Xms和-Xmx实际上是-XX:InitialHeapSize和-XX:MaxHeapSize的缩写。我们也可以直接使用这两个参数，它们所起得效果是一样的：

| `1`  | `$ java -XX:InitialHeapSize=128m -XX:MaxHeapSize=2g MyApp` |
| ---- | ---------------------------------------------------------- |
|      |                                                            |

需要注意的是，所有JVM关于初始\最大堆内存大小的输出都是使用它们的完整名称：“InitialHeapSize”和“InitialHeapSize”。所以当你查询一个正在运行的JVM的堆内存大小时，如使用-XX:+PrintCommandLineFlags参数或者通过JMX查询，你应该寻找“InitialHeapSize”和“InitialHeapSize”标志而不是“Xms”和“Xmx”。

**-XX:+HeapDumpOnOutOfMemoryError and -XX:HeapDumpPath**

如果我们没法为-Xmx（最大堆内存）设置一个合适的大小，那么就有可能面临内存溢出（OutOfMemoryError）的风险，这可能是我们使用JVM时面临的最可怕的猛兽之一。就同[另外一篇](http://blog.codecentric.de/en/2011/03/java-memory-configuration-and-monitoring-3rd-act/)关于这个主题的博文说的一样，导致内存溢出的根本原因需要仔细的定位。通常来说，分析堆内存快照（Heap Dump）是一个很好的定位手段，如果发生内存溢出时没有生成内存快照那就实在是太糟了，特别是对于那种JVM已经崩溃或者错误只出现在顺利运行了数小时甚至数天的生产系统上的情况。

幸运的是，我们可以通过设置-XX:+HeapDumpOnOutOfMemoryError 让JVM在发生内存溢出时自动的生成堆内存快照。有了这个参数，当我们不得不面对内存溢出异常的时候会节约大量的时间。默认情况下，堆内存快照会保存在JVM的启动目录下名为java_pid<pid>.hprof 的文件里（在这里<pid>就是JVM进程的进程号）。也可以通过设置-XX:HeapDumpPath=<path>来改变默认的堆内存快照生成路径，<path>可以是相对或者绝对路径。

虽然这一切听起来很不错，但有一点我们需要牢记。堆内存快照文件有可能很庞大，特别是当内存溢出错误发生的时候。因此，我们推荐将堆内存快照生成路径指定到一个拥有足够磁盘空间的地方。

**-XX:OnOutOfMemoryError**

当内存溢发生时，我们甚至可以可以执行一些指令，比如发个E-mail通知管理员或者执行一些清理工作。通过-XX:OnOutOfMemoryError 这个参数我们可以做到这一点，这个参数可以接受一串指令和它们的参数。在这里，我们将不会深入它的细节，但我们提供了它的一个例子。在下面的例子中，当内存溢出错误发生的时候，我们会将堆内存快照写到/tmp/heapdump.hprof 文件并且在JVM的运行目录执行脚本cleanup.sh

| `1`  | `$ java -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/heapdump.hprof -XX:OnOutOfMemoryError =``"sh ~/cleanup.sh"` `MyApp` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

 **-XX:PermSize and -XX:MaxPermSize**

永久代在堆内存中是一块独立的区域，它包含了所有JVM加载的类的对象表示。为了成功运行应用程序，JVM会加载很多类（因为它们依赖于大量的第三方库，而这又依赖于更多的库并且需要从里面将类加载进来）这就需要增加永久代的大小。我们可以使用-XX:PermSize 和-XX:MaxPermSize 来达到这个目的。其中-XX:MaxPermSize 用于设置永久代大小的最大值，-XX:PermSize 用于设置永久代初始大小。下面是一个简单的例子：

| `1`  | `$ java -XX:PermSize=128m -XX:MaxPermSize=256m MyApp` |
| ---- | ----------------------------------------------------- |
|      |                                                       |

请注意，这里设置的永久代大小并不会被包括在使用参数-XX:MaxHeapSize 设置的堆内存大小中。也就是说，通过-XX:MaxPermSize设置的永久代内存可能会需要由参数-XX:MaxHeapSize 设置的堆内存以外的更多的一些堆内存。

**-XX:InitialCodeCacheSize and -XX:ReservedCodeCacheSize**

JVM一个有趣的，但往往被忽视的内存区域是“代码缓存”，它是用来存储已编译方法生成的本地代码。代码缓存确实很少引起性能问题，但是一旦发生其影响可能是毁灭性的。如果代码缓存被占满，JVM会打印出一条警告消息，并切换到interpreted-only 模式：JIT编译器被停用，字节码将不再会被编译成机器码。因此，应用程序将继续运行，但运行速度会降低一个数量级，直到有人注意到这个问题。就像其他内存区域一样，我们可以自定义代码缓存的大小。相关的参数是-XX:InitialCodeCacheSize 和-XX:ReservedCodeCacheSize，它们的参数和上面介绍的参数一样，都是字节值。

**-XX:+UseCodeCacheFlushing**

如果代码缓存不断增长，例如，因为热部署引起的内存泄漏，那么提高代码的缓存大小只会延缓其发生溢出。为了避免这种情况的发生，我们可以尝试一个有趣的新参数：当代码缓存被填满时让JVM放弃一些编译代码。通过使用-XX:+UseCodeCacheFlushing 这个参数，我们至少可以避免当代码缓存被填满的时候JVM切换到interpreted-only 模式。不过，我仍建议尽快解决代码缓存问题发生的根本原因，如找出内存泄漏并修复它。

## 1.5 JVM实用参数（五）新生代垃圾回收

本部分，我们将关注堆(heap) 中一个主要区域，新生代(young generation)。首先我们会讨论为什么调整新生代的参数会对应用的性能如此重要，接着我们将学习新生代相关的JVM参数。

单纯从JVM的功能考虑，并不需要新生代，完全可以针对整个堆进行操作。**新生代存在的唯一理由是优化垃圾回收(GC)的性能。**更具体说，把堆划分为新生代和老年代有2个好处：简化了新对象的分配(只在新生代分配内存),可以更有效的清除不再需要的对象(即死对象)(新生代和老年代使用不同的GC算法)

通过广泛研究面向对象实现的应用，发现一个共同特点：很多对象的生存时间都很短。同时研究发现，新生对象很少引用生存时间长的对象。结合这2个特点，很明显 GC 会频繁访问新生对象，例如在堆中一个单独的区域，称之为新生代。在新生代中，GC可以快速标记回收”死对象”，而不需要扫描整个Heap中的存活一段时间的”老对象”。



SUN/Oracle 的HotSpot JVM 又把新生代进一步划分为3个区域：一个相对大点的区域，称为”伊甸园区(Eden)”；两个相对小点的区域称为”From 幸存区(survivor)”和”To 幸存区(survivor)”。按照规定,新对象会首先分配在 Eden 中(如果新对象过大，会直接分配在老年代中)。在GC中，Eden 中的对象会被移动到survivor中，直至对象满足一定的年纪(定义为熬过GC的次数),会被移动到老年代。

基于大多数新生对象都会在GC中被收回的假设。新生代的GC 使用复制算法。在GC前To 幸存区(survivor)保持清空,对象保存在 Eden 和 From 幸存区(survivor)中，GC运行时,Eden中的幸存对象被复制到 To 幸存区(survivor)。针对 From 幸存区(survivor)中的幸存对象，会考虑对象年龄,如果年龄没达到阀值(tenuring threshold)，对象会被复制到To 幸存区(survivor)。如果达到阀值对象被复制到老年代。复制阶段完成后，Eden 和From 幸存区中只保存死对象，可以视为清空。如果在复制过程中To 幸存区被填满了，剩余的对象会被复制到老年代中。最后 From 幸存区和 To幸存区会调换下名字，在下次GC时，To 幸存区会成为From 幸存区。

![https://blog.codecentric.de/files/2011/08/young_gc.png](https://ws2.sinaimg.cn/large/006tNc79ly1fz72whb7iej30n109lq2r.jpg)

上图演示GC过程，黄色表示死对象，绿色表示剩余空间，红色表示幸存对象

总结一下，对象一般出生在Eden区，年轻代GC过程中，对象在2个幸存区之间移动，如果对象存活到适当的年龄，会被移动到老年代。当对象在老年代死亡时，就需要更高级别的GC，更重量级的GC算法(复制算法不适用于老年代，因为没有多余的空间用于复制)

现在应该能理解为什么新生代大小非常重要了(译者,有另外一种说法：新生代大小并不重要，影响GC的因素主要是幸存对象的数量)，如果新生代过小，会导致新生对象很快就晋升到老年代中，在老年代中对象很难被回收。如果新生代过大，会发生过多的复制过程。我们需要找到一个合适大小，不幸的是，要想获得一个合适的大小，只能通过不断的测试调优。这就需要JVM参数了

**-XX:NewSize and -XX:MaxNewSize**
就像可以通过参数(-Xms and -Xmx) 指定堆大小一样，可以通过参数指定新生代大小。设置 XX:MaxNewSize 参数时，应该考虑到新生代只是整个堆的一部分，新生代设置的越大，老年代区域就会减少。一般不允许新生代比老年代还大，因为要考虑GC时最坏情况，所有对象都晋升到老年代。(译者:会发生OOM错误) -XX:MaxNewSize 最大可以设置为-Xmx/2 .

考虑性能，一般会通过参数 -XX:NewSize 设置新生代初始大小。如果知道新生代初始分配的对象大小(经过监控) ，这样设置会有帮助，可以节省新生代自动扩展的消耗。

**-XX:NewRatio**
可以设置新生代和老年代的相对大小。这种方式的优点是新生代大小会随着整个堆大小动态扩展。参数 -XX:NewRatio 设置老年代与新生代的比例。例如 -XX:NewRatio=3 指定老年代/新生代为3/1. 老年代占堆大小的 3/4 ，新生代占 1/4 .

如果针对新生代,同时定义绝对值和相对值,绝对值将起作用。下面例子：
`$ java -XX:NewSize=32m -XX:MaxNewSize=512m -XX:NewRatio=3 MyApp`

以上设置, JVM 会尝试为新生代分配四分之一的堆大小，但不会小于32MB或大于521MB

在设置新生代大小问题上，使用绝对值还是相对值，不存在通用准则 。如果了解应用的内存使用情况,设置固定大小的堆和新生代更有利，当然也可以设置相对值。如果对应用的内存使用一无所知,正确的做法是不要设置任何参数，如果应用运行良好。很好，我们不用做任何额外动作.如果遇到性能或OutOfMemoryErrors, 在调优之前，首先需要进行一系列有目的的监控测试，缩小问题的根源。

**-XX:SurvivorRatio**
参数 -XX:SurvivorRatio 与 -XX:NewRatio 类似，作用于新生代内部区域。-XX:SurvivorRatio 指定伊甸园区(Eden)与幸存区大小比例. 例如, -XX:SurvivorRatio=10 表示伊甸园区(Eden)是 幸存区To 大小的10倍(也是幸存区From的10倍).所以,伊甸园区(Eden)占新生代大小的10/12, 幸存区From和幸存区To 每个占新生代的1/12 .注意,两个幸存区永远是一样大的..

设定幸存区大小有什么作用? 假设幸存区相对伊甸园区(Eden)太小, 相应新生对象的伊甸园区(Eden)永远很大空间, 我们当然希望,如果这些对象在GC时全部被回收,伊甸园区(Eden)被清空,一切正常.然而,如果有一部分对象在GC中幸存下来, 幸存区只有很少空间容纳这些对象.结果大部分幸存对象在一次GC后，就会被转移到老年代 ,这并不是我们希望的.考虑相反情况, 假设幸存区相对伊甸园区(Eden)太大,当然有足够的空间，容纳GC后的幸存对象. 但是过小的伊甸园区(Eden),意味着空间将越快耗尽，增加新生代GC次数，这是不可接受的。

总之,我们希望最小化短命对象晋升到老年代的数量，同时也希望最小化新生代GC 的次数和持续时间.我们需要找到针对当前应用的折中方案, 寻找适合方案的起点是 了解当前应用中对象的年龄分布情况。

**-XX:+PrintTenuringDistribution**
参数 -XX:+PrintTenuringDistribution 指定JVM 在每次新生代GC时，输出幸存区中对象的年龄分布。例如:
`Desired survivor size 75497472 bytes, new threshold 15 (max 15)- age 1: 19321624 bytes, 19321624 total- age 2: 79376 bytes, 19401000 total- age 3: 2904256 bytes, 22305256 total`

第一行说明幸存区To大小为 75 MB. 也有关于老年代阀值(tenuring threshold)的信息, 老年代阀值，意思是对象从新生代移动到老年代之前，经过几次GC(即, 对象晋升前的最大年龄). 上例中,老年代阀值为15,最大也是15.

之后行表示，对于小于老年代阀值的每一个对象年龄,本年龄中对象所占字节 (如果当前年龄没有对象,这一行会忽略). 上例中,一次 GC 后幸存对象大约 19 MB, 两次GC 后幸存对象大约79 KB , 三次GC 后幸存对象大约 3 MB .每行结尾，显示直到本年龄全部对象大小.所以,最后一行的 total 表示幸存区To 总共被占用22 MB . 幸存区To 总大小为 75 MB ,当前老年代阀值为15，可以断定在本次GC中，没有对象会移动到老年代。现在假设下一次GC 输出为：

Desired survivor size 75497472 bytes, new threshold 2 (max 15)
- age 1: 68407384 bytes, 68407384 total
- age 2: 12494576 bytes, 80901960 total
- age 3: 79376 bytes, 80981336 total
- age 4: 2904256 bytes, 83885592 total

对比前一次老年代分布。明显的,年龄2和年龄3 的对象还保持在幸存区中，因为我们看到年龄3和4的对象大小与前一次年龄2和3的相同。同时发现幸存区中,有一部分对象已经被回收,因为本次年龄2的对象大小为 12MB ，而前一次年龄1的对象大小为 19 MB。最后可以看到最近的GC中，有68 MB 新对象，从伊甸园区移动到幸存区。

注意,本次GC 幸存区占用总大小 84 MB -大于75 MB. 结果,JVM 把老年代阀值从15降低到2，在下次GC时，一部分对象会强制离开幸存区，这些对象可能会被回收(如果他们刚好死亡)或移动到老年代。

**-XX:InitialTenuringThreshold, -XX:MaxTenuringThreshold and -XX:TargetSurvivorRatio**
参数 -XX:+PrintTenuringDistribution 输出中的部分值可以通过其它参数控制。通过 -XX:InitialTenuringThreshold 和 -XX:MaxTenuringThreshold 可以设定老年代阀值的初始值和最大值。另外,可以通过参数 -XX:TargetSurvivorRatio 设定幸存区的目标使用率.例如 , -XX:MaxTenuringThreshold=10 -XX:TargetSurvivorRatio=90 设定老年代阀值的上限为10,幸存区空间目标使用率为90%。

有多种方式,设置新生代行为，没有通用准则。我们必须清楚以下2中情况：
1 如果从年龄分布中发现，有很多对象的年龄持续增长，在到达老年代阀值之前。这表示 -XX:MaxTenuringThreshold 设置过大
2 如果 -XX:MaxTenuringThreshold 的值大于1，但是很多对象年龄从未大于1.应该看下幸存区的目标使用率。如果幸存区使用率从未到达，这表示对象都被GC回收，这正是我们想要的。 如果幸存区使用率经常达到，有些年龄超过1的对象被移动到老年代中。这种情况，可以尝试调整幸存区大小或目标使用率。

**-XX:+NeverTenure and -XX:+AlwaysTenure**
最后,我们介绍2个颇为少见的参数,对应2种极端的新生代GC情况.设置参数 -XX:+NeverTenure , 对象永远不会晋升到老年代.当我们确定不需要老年代时，可以这样设置。这样设置风险很大,并且会浪费至少一半的堆内存。相反设置参数 -XX:+AlwaysTenure, 表示没有幸存区,所有对象在第一次GC时，会晋升到老年代。
没有合理的场景使用这个参数。可以在测试环境中，看下这样设置会发生什么有趣的事.但是并不推荐使用这些参数.

结论
适当的配置新生代非常重要，有相当多的参数可以设置新生代。然而，单独调整新生代，而不考虑老年代是不可能优化成功的。当调整堆和GC设置时，我们总是应该同时考虑新生代和老年代。

在本系列的下面2部分，我们将讨论 HotSpot JVM 中老年代 GC 策略,我们会学习“吞吐量GC收集器” 和 “并发低延迟GC收集器”,也会了解收集器的基本准则，算法和调整参数.

## 1.6 JVM实用参数（六） 吞吐量收集器



在实践中我们发现对于大多数的应用领域，评估一个垃圾收集(GC)算法如何根据如下两个标准：

1. 吞吐量越高算法越好
2. 暂停时间越短算法越好

首先让我们来明确垃圾收集(GC)中的两个术语:吞吐量(throughput)和暂停时间(pause times)。 JVM在专门的线程(GC threads)中执行GC。 只要GC线程是活动的，它们将与应用程序线程(application threads)争用当前可用CPU的时钟周期。 简单点来说，吞吐量是指应用程序线程用时占程序总用时的比例。 例如，吞吐量99/100意味着100秒的程序执行时间应用程序线程运行了99秒， 而在这一时间段内GC线程只运行了1秒。

术语”暂停时间”是指一个时间段内应用程序线程让与GC线程执行而完全暂停。 例如，GC期间100毫秒的暂停时间意味着在这100毫秒期间内没有应用程序线程是活动的。 如果说一个正在运行的应用程序有100毫秒的“平均暂停时间”，那么就是说该应用程序所有的暂停时间平均长度为100毫秒。 同样，100毫秒的“最大暂停时间”是指该应用程序所有的暂停时间最大不超过100毫秒。

**吞吐量 VS 暂停时间**

高吞吐量最好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。 直觉上，吞吐量越高程序运行越快。 低暂停时间最好因为从最终用户的角度来看不管是GC还是其他原因导致一个应用被挂起始终是不好的。 这取决于应用程序的类型，有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。 因此，具有低的最大暂停时间是非常重要的，特别是对于一个交互式应用程序。

不幸的是”高吞吐量”和”低暂停时间”是一对相互竞争的目标（矛盾）。这样想想看，为了清晰起见简化一下：GC需要一定的前提条件以便安全地运行。 例如，必须保证应用程序线程在GC线程试图确定哪些对象仍然被引用和哪些没有被引用的时候不修改对象的状态。 为此，应用程序在GC期间必须停止(或者仅在GC的特定阶段，这取决于所使用的算法)。 然而这会增加额外的线程调度开销：直接开销是上下文切换，间接开销是因为缓存的影响。 加上JVM内部安全措施的开销，这意味着GC及随之而来的不可忽略的开销，将增加GC线程执行实际工作的时间。 因此我们可以通过尽可能少运行GC来最大化吞吐量，例如，只有在不可避免的时候进行GC，来节省所有与它相关的开销。

然而，仅仅偶尔运行GC意味着每当GC运行时将有许多工作要做，因为在此期间积累在堆中的对象数量很高。 单个GC需要花更多时间来完成， 从而导致更高的平均和最大暂停时间。 因此，考虑到低暂停时间，最好频繁地运行GC以便更快速地完成。 这反过来又增加了开销并导致吞吐量下降，我们又回到了起点。
综上所述，在设计（或使用）GC算法时​​，我们必须确定我们的目标：一个GC算法​​只可能针对两个目标之一（即只专注于最大吞吐量或最小暂停时间），或尝试找到一个二者的折衷。

**HotSpot虚拟机上的垃圾收集**

该系列的第五部分我们已经讨论过年轻代的垃圾收集器。 对于年老代，HotSpot虚拟机提供两类垃圾收集算法(除了新的G1垃圾收集算法)，第一类算法试图最大限度地提高吞吐量，而第二类算法试图最小化暂停时间。 今天我们的重点是第一类，”面向吞吐量”的垃圾收集算法。
我们希望把重点放在JVM配置参数上，所以我只会简要概述HotSpot提供的面向吞吐量(throughput-oriented)垃圾收集算法。 当年老代中由于缺乏空间导致对象分配失败时会触发垃圾收集器(事实上，”分配”的通常是指从年轻代提升到年老代的对象)。 从所谓的”GC根”(GC roots)开始，搜索堆中的可达对象并将其标记为活着的，之后，垃圾收集器将活着的对象移到年老代的一块无碎片(non-fragmented)内存块中，并标记剩余的内存空间是空闲的。 也就是说，我们不像复制策略那样移到一个不同的堆区域，像年轻代垃圾收集算法所做的那样。 相反地，我们把所有的对象放在一个堆区域中，从而对该堆区域进行碎片整理。 垃圾收集器使用一个或多个线程来执行垃圾收集。 当使用多个线程时，算法的不同步骤被分解，使得每个收集线程大多时候工作在自己的区域而不干扰其他线程。 在垃圾收集期间，所有的应用程序线程暂停，只有垃圾收集完成之后才会重新开始。 现在让我们来看看跟面向吞吐量垃圾收集算法有关的重要JVM配置参数。

**-XX:+UseSerialGC**

我们使用该标志来激活串行垃圾收集器，例如单线程面向吞吐量垃圾收集器。 无论年轻代还是年老代都将只有一个线程执行垃圾收集。 该标志被推荐用于只有单个可用处理器核心的JVM。 在这种情况下，使用多个垃圾收集线程甚至会适得其反，因为这些线程将争用CPU资源，造成同步开销，却从未真正并行运行。

**-XX:+UseParallelGC**

有了这个标志，我们告诉JVM使用多线程并行执行年轻代垃圾收集。 在我看来，Java 6中不应该使用该标志因为-XX:+UseParallelOldGC显然更合适。 需要注意的是Java 7中该情况改变了一点(详见本概述)，就是-XX:+UseParallelGC能达到-XX:+UseParallelOldGC一样的效果。

**-XX:+UseParallelOldGC**

该标志的命名有点不巧，因为”老”听起来像”过时”。 然而，”老”实际上是指年老代，这也解释了为什么-XX:+UseParallelOldGC要优于-XX:+UseParallelGC：除了激活年轻代并行垃圾收集，也激活了年老代并行垃圾收集。 当期望高吞吐量，并且JVM有两个或更多可用处理器核心时，我建议使用该标志。
作为旁注，HotSpot的并行面向吞吐量垃圾收集算法通常称为”吞吐量收集器”，因为它们旨在通过并行执行来提高吞吐量。

**-XX:ParallelGCThreads**

通过-XX:ParallelGCThreads=<value>我们可以指定并行垃圾收集的线程数量。 例如，-XX:ParallelGCThreads=6表示每次并行垃圾收集将有6个线程执行。 如果不明确设置该标志，虚拟机将使用基于可用(虚拟)处理器数量计算的默认值。 决定因素是由Java Runtime。availableProcessors()方法的返回值N，如果N<=8，并行垃圾收集器将使用N个垃圾收集线程，如果N>8个可用处理器，垃圾收集线程数量应为3+5N/8。
当JVM独占地使用系统和处理器时使用默认设置更有意义。 但是，如果有多个JVM(或其他耗CPU的系统)在同一台机器上运行，我们应该使用-XX:ParallelGCThreads来减少垃圾收集线程数到一个适当的值。 例如，如果4个以服务器方式运行的JVM同时跑在在一个具有16核处理器的机器上，设置-XX:ParallelGCThreads=4是明智的，它能使不同JVM的垃圾收集器不会相互干扰。

**-XX:-UseAdaptiveSizePolicy**

吞吐量垃圾收集器提供了一个有趣的(但常见，至少在现代JVM上)机制以提高垃圾收集配置的用户友好性。 这种机制被看做是HotSpot在Java 5中引入的”人体工程学”概念的一部分。 通过人体工程学，垃圾收集器能将堆大小动态变动像GC设置一样应用到不同的堆区域，只要有证据表明这些变动将能提高GC性能。 “提高GC性能”的确切含义可以由用户通过-XX:GCTimeRatio和-XX:MaxGCPauseMillis(见下文)标记来指定。
重要的是要知道人体工程学是默认激活的。 这很好，因为自适应行为是JVM最大优势之一。 不过，有时我们需要非常清楚对于特定应用什么样的设置是最合适的，在这些情况下，我们可能不希望JVM混乱我们的设置。 每当我们发现处于这种情况时，我们可以考虑通过-XX:-UseAdaptiveSizePolicy停用一些人体工程学。

**-XX:GCTimeRatio**

通过-XX:GCTimeRatio=<value>我们告诉JVM吞吐量要达到的目标值。 更准确地说，-XX:GCTimeRatio=N指定目标应用程序线程的执行时间(与总的程序执行时间)达到N/(N+1)的目标比值。 例如，通过-XX:GCTimeRatio=9我们要求应用程序线程在整个执行时间中至少9/10是活动的(因此，GC线程占用其余1/10)。 基于运行时的测量，JVM将会尝试修改堆和GC设置以期达到目标吞吐量。 -XX:GCTimeRatio的默认值是99，也就是说，应用程序线程应该运行至少99%的总执行时间。

**-XX:MaxGCPauseMillis**

通过-XX:GCTimeRatio=<value>告诉JVM最大暂停时间的目标值(以毫秒为单位)。 在运行时，吞吐量收集器计算在暂停期间观察到的统计数据(加权平均和标准偏差)。 如果统计表明正在经历的暂停其时间存在超过目标值的风险时，JVM会修改堆和GC设置以降低它们。 需要注意的是，年轻代和年老代垃圾收集的统计数据是分开计算的，还要注意，默认情况下，最大暂停时间没有被设置。
如果最大暂停时间和最小吞吐量同时设置了目标值，实现最大暂停时间目标具有更高的优先级。 当然，无法保证JVM将一定能达到任一目标，即使它会努力去做。 最后，一切都取决于手头应用程序的行为。
当设置最大暂停时间目标时，我们应注意不要选择太小的值。 正如我们现在所知道的，为了保持低暂停时间，JVM需要增加GC次数，那样可能会严重影响可达到的吞吐量。 这就是为什么对于要求低暂停时间作为主要目标的应用程序(大多数是Web应用程序)，我会建议不要使用吞吐量收集器，而是选择CMS收集器。 CMS收集器是本系列下一部分的主题。

## 1.7 JVM实用参数（七）CMS收集器

HotSpot JVM的并发标记清理收集器(CMS收集器)的主要目标就是：低应用停顿时间。该目标对于大多数交互式应用很重要，比如web应用。在我们看一下有关JVM的参数之前,让我们简要回顾CMS收集器的操作和使用它时可能出现的主要挑战。

就像吞吐量收集器(参见本系列的[第6部分](http://ifeve.com/useful-jvm-flags-part-6-throughput-collector/)),CMS收集器处理老年代的对象,然而其操作要复杂得多。吞吐量收集器总是暂停应用程序线程，并且可能是相当长的一段时间，然而这能够使该算法安全地忽略应用程序。相比之下，CMS收集器被设计成在大多数时间能与应用程序线程并行执行，仅仅会有一点(短暂的)停顿时间。GC与应用程序并行的缺点就是，可能会出现各种同步和数据不一致的问题。为了实现安全且正确的并发执行，CMS收集器的GC周期被分为了好几个连续的阶段。

**CMS收集器的过程**

CMS收集器的GC周期由6个阶段组成。其中4个阶段(名字以Concurrent开始的)与实际的应用程序是并发执行的，而其他2个阶段需要暂停应用程序线程。

1. 初始标记：为了收集应用程序的对象引用需要暂停应用程序线程，该阶段完成后，应用程序线程再次启动。
2. 并发标记：从第一阶段收集到的对象引用开始，遍历所有其他的对象引用。
3. 并发预清理：改变当运行第二阶段时，由应用程序线程产生的对象引用，以更新第二阶段的结果。
4. 重标记：由于第三阶段是并发的，对象引用可能会发生进一步改变。因此，应用程序线程会再一次被暂停以更新这些变化，并且在进行实际的清理之前确保一个正确的对象引用视图。这一阶段十分重要，因为必须避免收集到仍被引用的对象。
5. 并发清理：所有不再被应用的对象将从堆里清除掉。
6. 并发重置：收集器做一些收尾的工作，以便下一次GC周期能有一个干净的状态。

一个常见的误解是,CMS收集器运行是完全与应用程序并发的。我们已经看到，事实并非如此，即使“stop-the-world”阶段相对于并发阶段的时间很短。

应该指出，尽管CMS收集器为老年代垃圾回收提供了几乎完全并发的解决方案，然而年轻代仍然通过“stop-the-world”方法来进行收集。对于交互式应用，停顿也是可接受的，背后的原理是年轻带的垃圾回收时间通常是相当短的。

**挑战**

当我们在真实的应用中使用CMS收集器时，我们会面临两个主要的挑战，可能需要进行调优：

1. 堆碎片
2. 对象分配率高

堆碎片是有可能的，不像吞吐量收集器，CMS收集器并没有任何碎片整理的机制。因此，应用程序有可能出现这样的情形，即使总的堆大小远没有耗尽，但却不能分配对象——仅仅是因为没有足够连续的空间完全容纳对象。当这种事发生后，并发算法不会帮上任何忙，因此，万不得已JVM会触发Full GC。回想一下，Full GC 将运行吞吐量收集器的算法，从而解决碎片问题——但却暂停了应用程序线程。因此尽管CMS收集器带来完全的并发性，但仍然有可能发生长时间的“stop-the-world”的风险。这是“设计”，而不能避免的——我们只能通过调优收集器来它的可能性。想要100%保证避免”stop-the-world”，对于交互式应用是有问题的。

第二个挑战就是应用的对象分配率高。如果获取对象实例的频率高于收集器清除堆里死对象的频率，并发算法将再次失败。从某种程度上说，老年代将没有足够的可用空间来容纳一个从年轻代提升过来的对象。这种情况被称为“并发模式失败”，并且JVM会执行堆碎片整理：触发Full GC。

当这些情形之一出现在实践中时(经常会出现在生产系统中)，经常被证实是老年代有大量不必要的对象。一个可行的办法就是增加年轻代的堆大小，以防止年轻代短生命的对象提前进入老年代。另一个办法就似乎利用分析器，快照运行系统的堆转储，并且分析过度的对象分配，找出这些对象，最终减少这些对象的申请。

下面我看看大多数与CMS收集器调优相关的JVM标志参数。

**-XX：+UseConcMarkSweepGC**

该标志首先是激活CMS收集器。默认HotSpot JVM使用的是并行收集器。

**-XX：UseParNewGC**

当使用CMS收集器时，该标志激活年轻代使用多线程并行执行垃圾回收。这令人很惊讶，我们不能简单在并行收集器中重用-XX：UserParNewGC标志，因为概念上年轻代用的算法是一样的。然而，对于CMS收集器，年轻代GC算法和老年代GC算法是不同的，因此年轻代GC有两种不同的实现，并且是两个不同的标志。

注意最新的JVM版本，当使用-XX：+UseConcMarkSweepGC时，-XX：UseParNewGC会自动开启。因此，如果年轻代的并行GC不想开启，可以通过设置-XX：-UseParNewGC来关掉。

**-XX：+CMSConcurrentMTEnabled**

当该标志被启用时，并发的CMS阶段将以多线程执行(因此，多个GC线程会与所有的应用程序线程并行工作)。该标志已经默认开启，如果顺序执行更好，这取决于所使用的硬件，多线程执行可以通过-XX：-CMSConcurremntMTEnabled禁用。

 **-XX：ConcGCThreads**

标志-XX：ConcGCThreads=<value>(早期JVM版本也叫-XX:ParallelCMSThreads)定义并发CMS过程运行时的线程数。比如value=4意味着CMS周期的所有阶段都以4个线程来执行。尽管更多的线程会加快并发CMS过程，但其也会带来额外的同步开销。因此，对于特定的应用程序，应该通过测试来判断增加CMS线程数是否真的能够带来性能的提升。

如果还标志未设置，JVM会根据并行收集器中的-XX：ParallelGCThreads参数的值来计算出默认的并行CMS线程数。该公式是ConcGCThreads = (ParallelGCThreads + 3)/4。因此，对于CMS收集器， `-XX:ParallelGCThreads标志不仅影响“stop-the-world”垃圾收集阶段，还影响并发阶段。`

总之，有不少方法可以配置CMS收集器的多线程执行。正是由于这个原因,建议第一次运行CMS收集器时使用其默认设置, 然后如果需要调优再进行测试。只有在生产系统中测量(或类生产测试系统)发现应用程序的暂停时间的目标没有达到 , 就可以通过这些标志应该进行GC调优。

**-XX:CMSInitiatingOccupancyFraction**

当堆满之后，并行收集器便开始进行垃圾收集，例如，当没有足够的空间来容纳新分配或提升的对象。对于CMS收集器，长时间等待是不可取的，因为在并发垃圾收集期间应用持续在运行(并且分配对象)。因此，为了在应用程序使用完内存之前完成垃圾收集周期，CMS收集器要比并行收集器更先启动。

因为不同的应用会有不同对象分配模式，JVM会收集实际的对象分配(和释放)的运行时数据，并且分析这些数据，来决定什么时候启动一次CMS垃圾收集周期。为了引导这一过程， JVM会在一开始执行CMS周期前作一些线索查找。该线索由 `-XX:CMSInitiatingOccupancyFraction=<value>来设置，该值代表老年代堆空间的使用率。比如，value=75意味着第一次CMS垃圾收集会在老年代被占用75%时被触发。通常CMSInitiatingOccupancyFraction的默认值为68(之前很长时间的经历来决定的)。`

**-XX：+UseCMSInitiatingOccupancyOnly**

我们用-XX+UseCMSInitiatingOccupancyOnly标志来命令JVM不基于运行时收集的数据来启动CMS垃圾收集周期。而是，当该标志被开启时，JVM通过CMSInitiatingOccupancyFraction的值进行每一次CMS收集，而不仅仅是第一次。然而，请记住大多数情况下，JVM比我们自己能作出更好的垃圾收集决策。因此，只有当我们充足的理由(比如测试)并且对应用程序产生的对象的生命周期有深刻的认知时，才应该使用该标志。

**-XX:+CMSClassUnloadingEnabled**

相对于并行收集器，CMS收集器默认不会对永久代进行垃圾回收。如果希望对永久代进行垃圾回收，可用设置标志-XX:+CMSClassUnloadingEnabled。在早期JVM版本中，要求设置额外的标志-XX:+CMSPermGenSweepingEnabled。注意，即使没有设置这个标志，一旦永久代耗尽空间也会尝试进行垃圾回收，但是收集不会是并行的，而再一次进行Full GC。

**-XX:+CMSIncrementalMode**

该标志将开启CMS收集器的增量模式。增量模式经常暂停CMS过程，以便对应用程序线程作出完全的让步。因此，收集器将花更长的时间完成整个收集周期。因此，只有通过测试后发现正常CMS周期对应用程序线程干扰太大时，才应该使用增量模式。由于现代服务器有足够的处理器来适应并发的垃圾收集，所以这种情况发生得很少。

**-XX:+ExplicitGCInvokesConcurrent and -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses**

如今,被广泛接受的最佳实践是避免显式地调用GC(所谓的“系统GC”)，即在应用程序中调用system.gc()。然而，这个建议是不管使用的GC算法的，值得一提的是，当使用CMS收集器时，系统GC将是一件很不幸的事，因为它默认会触发一次Full GC。幸运的是，有一种方式可以改变默认设置。标志-XX:+ExplicitGCInvokesConcurrent命令JVM无论什么时候调用系统GC，都执行CMS GC，而不是Full GC。第二个标志-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses保证当有系统GC调用时，永久代也被包括进CMS垃圾回收的范围内。因此，通过使用这些标志，我们可以防止出现意料之外的”stop-the-world”的系统GC。

**-XX:+DisableExplicitGC**

然而在这个问题上…这是一个很好提到- XX:+ DisableExplicitGC标志的机会，该标志将告诉JVM完全忽略系统的GC调用(不管使用的收集器是什么类型)。对于我而言，该标志属于默认的标志集合中，可以安全地定义在每个JVM上运行，而不需要进一步思考。

## 1.8 JVM实用参数（八）GC日志

本系列的最后一部分是有关垃圾收集（GC）日志的JVM参数。GC日志是一个很重要的工具，它准确记录了每一次的GC的执行时间和执行结果，通过分析GC日志可以优化堆设置和GC设置，或者改进应用程序的对象分配模式。

**-XX:+PrintGC**

参数-XX:+PrintGC（或者-verbose:gc）开启了简单GC日志模式，为每一次新生代（young generation）的GC和每一次的Full GC打印一行信息。下面举例说明：

| `1`  | `[GC 246656K->243120K(376320K), ``0.0929090` `secs]` |
| ---- | ---------------------------------------------------- |
|      |                                                      |

| `2`  | `[Full GC 243120K->241951K(629760K), ``1.5589690` `secs]` |
| ---- | --------------------------------------------------------- |
|      |                                                           |

每行开始首先是GC的类型（可以是“GC”或者“Full GC”），然后是在GC之前和GC之后已使用的堆空间，再然后是当前的堆容量，最后是GC持续的时间（以秒计）。

第一行的意思就是GC将已使用的堆空间从246656K减少到243120K，当前的堆容量（译者注：GC发生时）是376320K，GC持续的时间是0.0929090秒。

简单模式的GC日志格式是与GC算法无关的，日志也没有提供太多的信息。在上面的例子中，我们甚至无法从日志中判断是否GC将一些对象从young generation移到了old generation。所以详细模式的GC日志更有用一些。

**-XX:PrintGCDetails**

如果不是使用-XX:+PrintGC，而是-XX:PrintGCDetails，就开启了详细GC日志模式。在这种模式下，日志格式和所使用的GC算法有关。我们首先看一下使用Throughput垃圾收集器在young generation中生成的日志。为了便于阅读这里将一行日志分为多行并使用缩进。

| `1`  | `[GC` |
| ---- | ----- |
|      |       |

| `2`  | `    ``[PSYoungGen: 142816K->10752K(142848K)] 246648K->243136K(375296K), ``0.0935090` `secs` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

| `3`  | `]`  |
| ---- | ---- |
|      |      |

| `4`  | `[Times: user=``0.55` `sys=``0.10``, real=``0.09` `secs]` |
| ---- | --------------------------------------------------------- |
|      |                                                           |

我们可以很容易发现：这是一次在young generation中的GC，它将已使用的堆空间从246648K减少到了243136K，用时0.0935090秒。此外我们还可以得到更多的信息：所使用的垃圾收集器（即PSYoungGen）、young generation的大小和使用情况（在这个例子中“PSYoungGen”垃圾收集器将young generation所使用的堆空间从142816K减少到10752K）。

既然我们已经知道了young generation的大小，所以很容易判定发生了GC，因为young generation无法分配更多的对象空间：已经使用了142848K中的142816K。我们可以进一步得出结论，多数从young generation移除的对象仍然在堆空间中，只是被移到了old generation：通过对比绿色的和蓝色的部分可以发现即使young generation几乎被完全清空（从142816K减少到10752K），但是所占用的堆空间仍然基本相同（从246648K到243136K）。

详细日志的“Times”部分包含了GC所使用的CPU时间信息，分别为操作系统的用户空间和系统空间所使用的时间。同时，它显示了GC运行的“真实”时间（0.09秒是0.0929090秒的近似值）。如果CPU时间（译者注：0.55秒+0.10秒）明显多于”真实“时间（译者注：0.09秒），我们可以得出结论：GC使用了多线程运行。这样的话CPU时间就是所有GC线程所花费的CPU时间的总和。实际上我们的例子中的垃圾收集器使用了8个线程。

接下来看一下Full GC的输出日志

| `1`  | `[Full GC` |
| ---- | ---------- |
|      |            |

| `2`  | `    ``[PSYoungGen: 10752K->9707K(142848K)]` |
| ---- | -------------------------------------------- |
|      |                                              |

| `3`  | `    ``[ParOldGen: 232384K->232244K(485888K)] 243136K->241951K(628736K)` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

| `4`  | `    ``[PSPermGen: 3162K->3161K(21504K)], ``1.5265450` `secs` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

| `5`  | `]`  |
| ---- | ---- |
|      |      |

除了关于young generation的详细信息，日志也提供了old generation和permanent generation的详细信息。对于这三个generations，一样也可以看到所使用的垃圾收集器、堆空间的大小、GC前后的堆使用情况。需要注意的是显示堆空间的大小等于young generation和old generation各自堆空间的和。以上面为例，堆空间总共占用了241951K，其中9707K在young generation，232244K在old generation。Full GC持续了大约1.53秒，用户空间的CPU执行时间为10.96秒，说明GC使用了多线程（和之前一样8个线程）。

对不同generation详细的日志可以让我们分析GC的原因，如果某个generation的日志显示在GC之前，堆空间几乎被占满，那么很有可能就是这个generation触发了GC。但是在上面的例子中，三个generation中的任何一个都不是这样的，在这种情况下是什么原因触发了GC呢。对于Throughput垃圾收集器，在某一个generation被过度使用之前，GC ergonomics（参考本系列第6节）决定要启动GC。

Full GC也可以通过显式的请求而触发，可以是通过应用程序，或者是一个外部的JVM接口。这样触发的GC可以很容易在日志里分辨出来，因为输出的日志是以“Full GC(System)”开头的，而不是“Full GC”。

对于Serial垃圾收集器，详细的GC日志和Throughput垃圾收集器是非常相似的。唯一的区别是不同的generation日志可能使用了不同的GC算法（例如：old generation的日志可能以Tenured开头，而不是ParOldGen）。使用垃圾收集器作为一行日志的开头可以方便我们从日志就判断出JVM的GC设置。

对于CMS垃圾收集器，young generation的详细日志也和Throughput垃圾收集器非常相似，但是old generation的日志却不是这样。对于CMS垃圾收集器，在old generation中的GC是在不同的时间片内与应用程序同时运行的。GC日志自然也和Full GC的日志不同。而且在不同时间片的日志夹杂着在此期间young generation的GC日志。但是了解了上面介绍的GC日志的基本元素，也不难理解在不同时间片内的日志。只是在解释GC运行时间时要特别注意，由于大多数时间片内的GC都是和应用程序同时运行的，所以和那种独占式的GC相比，GC的持续时间更长一些并不说明一定有问题。

正如我们在第7节中所了解的，即使CMS垃圾收集器没有完成一个CMS周期，Full GC也可能会发生。如果发生了GC，在日志中会包含触发Full GC的原因，例如众所周知的”concurrent mode failure“。

为了避免过于冗长，我这里就不详细说明CMS垃圾收集器的日志了。另外，CMS垃圾收集器的作者做了详细的说明（在这里），强烈建议阅读。

**-XX:+PrintGCTimeStamps和-XX:+PrintGCDateStamps**

使用-XX:+PrintGCTimeStamps可以将时间和日期也加到GC日志中。表示自JVM启动至今的时间戳会被添加到每一行中。例子如下：

| `1`  | `0.185``: [GC 66048K->53077K(251392K), ``0.0977580` `secs]` |
| ---- | ----------------------------------------------------------- |
|      |                                                             |

| `2`  | `0.323``: [GC 119125K->114661K(317440K), ``0.1448850` `secs]` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

| `3`  | `0.603``: [GC 246757K->243133K(375296K), ``0.2860800` `secs]` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

如果指定了-XX:+PrintGCDateStamps，每一行就添加上了绝对的日期和时间。

| `1`  | `2014``-``01``-03T12:``08``:``38.102``-``0100``: [GC 66048K->53077K(251392K), ``0.0959470` `secs]` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

| `2`  | `2014``-``01``-03T12:``08``:``38.239``-``0100``: [GC 119125K->114661K(317440K), ``0.1421720` `secs]` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

| `3`  | `2014``-``01``-03T12:``08``:``38.513``-``0100``: [GC 246757K->243133K(375296K), ``0.2761000` `secs]` |
| ---- | ------------------------------------------------------------ |
|      |                                                              |

如果需要也可以同时使用两个参数。推荐同时使用这两个参数，因为这样在关联不同来源的GC日志时很有帮助。

**-Xloggc**

缺省的GC日志时输出到终端的，使用-Xloggc:也可以输出到指定的文件。需要注意这个参数隐式的设置了参数-XX:+PrintGC和-XX:+PrintGCTimeStamps，但为了以防在新版本的JVM中有任何变化，我仍建议显示的设置这些参数。

**可管理的JVM参数**

一个常常被讨论的问题是在生产环境中GC日志是否应该开启。因为它所产生的开销通常都非常有限，因此我的答案是需要开启。但并不一定在启动JVM时就必须指定GC日志参数。

HotSpot JVM有一类特别的参数叫做可管理的参数。对于这些参数，可以在运行时修改他们的值。我们这里所讨论的所有参数以及以“PrintGC”开头的参数都是可管理的参数。这样在任何时候我们都可以开启或是关闭GC日志。比如我们可以使用JDK自带的jinfo工具来设置这些参数，或者是通过JMX客户端调用`HotSpotDiagnostic MXBean的`setVMOption方法来设置这些参数。



# 2. JVM 优化经验总结

## 2.1 概述

并不是每个程序都需要调优。如果一个程序性能表现和预期一样，你不必付出额外的精力去提高它的性能。然而，在程序调试完成之后，很难马上就满足它的性能需求，于是就有了调优这项工作。无论哪种编程语言，对应用程序进行调优都需要丰富的技术知识并且注意力高度集中。另外，你也不应该用相同的方式对两个程序调优，因为每个程序都有它自己独特的运作方式和不同的资源使用方式。正因如此，调优比写程序需要更多基础知识。例如，你需要熟悉虚拟机、操作系统和计算机架构。而当你面对在这些知识基础上编写的程序时，就能成功地对它进行调优。

有时调优Java程序只需要修改JVM参数，比如GC的参数。但也有些时候需要修改程序代码。无论那种方法，你首先都需要监控执行Java程序的进程。因此本文会讲解下面几个问题：

- **怎样监控Java程序？**
- **应该给JVM设置怎样的参数？**
- **如何确定是否需要修改代码？**

## 2.2 对Java程序进行调优的必要知识

Java程序在Java虚拟机中运行。因此为了进行调优，你需要理解JVM的工作流程。我之前有一篇博文[Understanding JVM Internals](http://www.cubrid.org/blog/dev-platform/understanding-jvm-internals/)，将让你对JVM有深入的了解。

本文中有关JVM运作过程的知识主要关于GC和Hotspot。尽管只有这两方面的知识可能无法对所有的Java程序进行调优，但是这两个因素在大多数情况下都影响着Java程序的性能。

值得注意的是，从操作系统的角度来看，JVM也是一个应用程序进程。为了给JVM创造良好的运行环境，你还需要对操作系统分配资源的过程有所了解。这意味着，想要调优Java程序，除了JVM你也应该理解操作系统或者硬件的工作方式。

需要具有的知识还有Java这门语言本身。另外理解锁和并发、类加载和对象创建都是非常重要的。

当开始调优Java程序时，你应该整合以上各方面的知识来完成工作。

## 2.3 Java程序性能调优的过程

图1是一张Java程序性能调优的流程图，摘自由Charlie Hunt和Binu John所著的*Java Performance*。

![](https://ws4.sinaimg.cn/large/006tNc79ly1fz73xli3ilj30d20lpgmh.jpg)

图1：Java程序性能调优的过程

## 2.4 JVM分布式模型

**JVM分布式模型**用于决定是在一个JVM还是多个JVM上执行Java程序。你可以根据其有效性、响应能力和可维护性来进行选择。当在多台服务器上运行JVM时，你也可以选择将多个JVM运行于一台服务器或者每台服务器运行一个JVM。例如，对于每台服务器，你可以运行一个使用8GB堆内存的JVM，也可以运行4个使用2GB的JVM。你理应根据处理器内核的个数还有程序的特性来决定这个数量。当优先考虑响应能力时， 使用2GB的堆内存会优于8GB的，原因是这样能在更短的时间内完成Full GC。当然，8GB的堆内存可以降低Full GC的频率。如果你的程序使用了内部缓存，还可以通过增加缓存命中率来提高响应能力。综上所述，选择合适的模型需要考虑应用程序的特性，然后在各种模型中 选定一个能够扬长避短的。

## 2.5 JVM架构

选择JVM其实就是决定使用32位还是64位的JVM。在相同的条件下，你最好用32位的。因为32位的JVM比64位性能更好。然而，32位 JVM最大支持的堆内存是4GB（无论在32位操作系统还是64位的上，实际可分配的大小都只有2-3GB）。如果需要更大的堆内存，还是用64位的 JVM比较合适。

**表1：性能比较（数据来源）**

| 测试基准             | 时间（秒） | 系数  |
| -------------------- | ---------- | ----- |
| C++ Opt              | 23         | 1.0x  |
| C++ Dbg              | 197        | 8.6x  |
| Java 64-bit          | 134        | 5.8x  |
| Java 32-bit          | 290        | 12.6x |
| Java 32-bit GC*      | 106        | 4.6x  |
| Java 32-bit SPEC GC* | 89         | 3.7x  |
| Scala                | 82         | 3.6x  |
| Scala low-level*     | 67         | 2.9x  |
| Scala low-level GC*  | 58         | 2.5x  |
| Go 6g                | 161        | 7.0x  |
| Go Pro*              | 126        | 5.5x  |

下一步就是运行程序来测试它的性能。这个过程包括GC调优、改变操作系统设置和修改代码。对于这些工作，你可以使用系统监视工具或者性能分析工具。

**注意：**针对响应能力的调优和针对吞吐量的调优可能使用不同的方法。如果经常性地发生[stop-the-word](http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/)（串行GC暂时中断程序执行），程序的响应能力就会被降低。比如在高吞吐量时执行Full GC。不要忘记，在调优时往往有得有失。这样需要折衷处理的事情不仅发生在响应能力和吞吐量之间。例如使用更多的CPU资源来降低内存的使用，或者不得不忍受响应能力和吞吐量其中一个性能指标的下降。相反的情况同样可能发生，实际的调优应该根据各指标的优先级来执行。

上面**图1**中的流程展示了几乎可用于所有Java程序的性能调优过程，包括Swing应用。然而，对于我们公司[NHN](http://www.cubrid.org/blog/tags/NHN/)用于提供网络服务的服务器端程序来说，这个方法多少有些不合适。下面**图2**中的流程是根据**图1**修改而来，它更简单，也更适合NHN。

![](https://ws1.sinaimg.cn/large/006tNc79ly1fz75emq0psj308g0eqjro.jpg)

图2：对HNH的Java程序的调优过程

其中，**Select JVM**表示尽可能使用32位的JVM，除非你需要用64位的JVM来维护一个数GB的缓存。

现在，跟随**图2**中的流程，你会了解到每一步具体的工作。

## 2.6 JVM参数

我会主要讲解如何为Web服务端程序设置合适的JVM参数。尽管不一定适合所有的案例，但是**最好的GC算法**是[Concurrent Mark Sweep](http://www.cubrid.org/blog/dev-platform/understanding-java-garbage-collection/)（CMS垃圾回收），特别是对于Web服务端程序。因为**低延迟**是非常重要的。当然，在使用CMS时，由于新生代空间（New Area）的分配，可能发生较长时间的stop-the-world现象，不过调整新生代空间的大小或者它和整个堆空间的比例可能解决这个问题。

指定新生代空间的大小和指定整个对堆内存的大小同样重要。你最好使用`–XX:NewRatio`来指定新生代和整个堆的大小比例，或者直接用`–XX:NewSize`来指定所需的新生代空间。这个配置是非常必要的，因为大部分对象都不会存活很久。在Web程序中，除了缓存数据，其他多数对象都只在`HttpRequest`到`HttpResponse`期间创建。这个时间几乎不会超过1秒，表示这些对象的存活时间也不会超过1秒。如果新生代空间不够大，对象会被转移到老年代空间，以便腾出地方给新对象使用。老年代空间（Old Area）垃圾回收的代价是比新生代空间大的多的，因此很需要设置一个充足的新生代空间。

然而，当新生代空间的大小超过一个特定的水平，程序的响应能力会被降低。因为新生代空间的垃圾回收过程，基本上是将数据从一个Survivor Area复制到另外一个（From Space和To Space）。另外，stop-the-world的现象在新生代空间和老年代空间执行垃圾回收时都会发生。如果新生代空间变大，那么Survivor Area的空间也会更大，于是每次复制的数据就更多。基于这样一种特性，我们应该通过指定不同操作系统中HotSpot JVM的`NewRatio`参数来分配合适大小的新生代空间。

**表2：不同操作系统和配置下NewRatio的默认值**

| 操作系统及参数 | 默认-XX:NewRatio |
| -------------- | ---------------- |
| Sparc -server  | 2                |
| Sparc -client  | 8                |
| x86 -server    | 8                |
| x86 -client    | 12               |

如果设置了`NewRatio`，那么整个堆空间的`1/(NewRatio +1)`就是新生代空间的大小。上表可以看出**Sparc -server**的NewRatio默认值很小，因为相比**x86**的操作系统，Sparc以前更多用于高端应用，这个值就是为它们设置的。但现在x86操作系统的性能有很大提升，使用它们作为服务器已经很普遍了。因此指定NewRatio为2或者3是更好的选择，就和**Sparc -server**上的配置一样。

另外，你还可以通过指定`NewSize`和`MaxNewSize`来代替NewRatio。那么新生代空间创建时的大小就是指定的NewSize，随后可以一直增长到MaxNewSize的值。Eden（新创建对象存放的区域）和Survivor Area两个区域会随比例增加。就和你为-Xms（**译者注：**原文是-Xs，应该是笔误）和-Xmx设置相同的值一样，将MaxSize和 MaxNewSize设置为相同的也是一个好选择。

如果同时指定了NewRatio和NewSize，你应该使用更大的那个。于是，当堆空间被创建时，你可以用过下面的表达式计算初始新生代空间的大小：

```shell
`min(MaxNewSize, max(NewSize, heap/(NewRatio+``1``)))`
```

无论如何，仅通过一次尝试就找到合适的堆空间和新生代空间大小是不可能的。根据我在NHN运行Web服务器的经验，建议使用下面的JVM参数来运行Java程序。监控在这些参数的条件下程序的性能表现之后，你就能够选择更合适的GC算法或者配置。

**表3：推荐的JVM参数**



| 类型                        | 参数                                                         |
| --------------------------- | ------------------------------------------------------------ |
| 运行模式                    | -sever                                                       |
| 整个堆内存大小              | 为-Xms和-Xmx设置相同的值。                                   |
| 新生代空间大小              | -XX:NewRatio: 2到4. -XX:NewSize=? –XX:MaxNewSize=?. 使用NewSize代替NewRatio也是可以的。 |
| 持久代空间大小              | -XX:PermSize=256m -XX:MaxPermSize=256m. 设置一个在运行中不会出现问题的值即可，这个参数不影响性能。 |
| GC日志                      | -Xloggc:$CATALINA_BASE/logs/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps. 记录GC日志并不会特别地影响Java程序性能，推荐你尽可能记录日志。 |
| GC算法                      | -XX:+UseParNewGC -XX:+CMSParallelRemarkEnabled -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=75. 一般来说推荐使用这些配置，但是根据程序不同的特性，其他的也有可能更好。 |
| 发生OOM时创建堆内存转储文件 | -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=$CATALINA_BASE/logs |
| 发生OOM后的操作             | -XX:OnOutOfMemoryError=$CATALINA_HOME/bin/stop.sh 或 -XX:OnOutOfMemoryError=$CATALINA_HOME/bin/restart.sh. 记录内存转储文件后，为了管理的需要执行一个合适的操作。 |

## 2.7 测定程序的性能

为了得到程序的性能表现，需要以下这些信息：

- **系统吞吐量（TPS、OPS）**：从整体概念上理解程序的性能。
- **每秒请求数（Request Per Second – RPS）**：严格来说，RPS和单纯的响应能力是不同的，但是你可以把它理解为响应能力。通过这个指标，你能够了解到用户需要多长时间才能得到请求的结果。
- **RPS的标准差**：如果可能的话，还有必要包括事件的RPS。一旦出现了偏差，你应该检查GC或者网络系统。

为了得到更准确的性能表现，你应该等到程序彻底启动完成后再进行测量，因为字节码随后会被HotSpot JIT编译为本地机器码。总体来说，需要在程序加载完指定功能后，用[nGrinder](http://www.nhnopensource.org/ngrinder/)等工具测试至少10分钟。

## 2.8 切实地调优

如果nGrinder测试的结果满足了预期，那么你不需要对程序进行性能调优。如果没有达到预期结果，你就应该执行调优来解决问题。接下来会通过实例讲解方法。

## 2.9 stop-the-world耗时过长

stop-the-world耗时过长可能是由于GC参数不合理或者代码实现不正确。你可以通过分析工具或堆内存转储文件（Heap dump）来定位问题，比如检查堆内存中对象的类型和数量。如果在其中找到了很多不必要的对象，那么最好去改进代码。如果没有发现创建对象的过程中有特别的问题，那么最好单纯地修改GC参数。

为了适当地调整GC参数，你需要获取一段足够长时间的GC日志，还必须知道哪些情况会导致长时间的stop-the-world。想了解更多关于如何选择合适的GC参数，可以阅读我同事的一篇博文：[How to Monitor Java Garbage Collection](http://www.cubrid.org/blog/dev-platform/how-to-monitor-java-garbage-collection/)。

## 2.10 CPU使用率过低

当系统发生阻塞，吞吐量和CPU使用率都会降低。这可能是由于网络系统或者并发的问题。为了解决这个问题，你可以分析线程转储信息（Thread dump）或者使用分析工具。阅读这篇文章可以获得更多关于线程转储分析的知识：[How to Analyze Java Thread Dumps](http://www.cubrid.org/blog/dev-platform/how-to-analyze-java-thread-dumps/)。

你可以使用商业的分析工具对线程锁进行精确的分析，不过大部分时候，只需使用**JVisualVM**中的CPU分析器，就能获得足够的信息。

## 2.11 CPU使用率过高

如果吞吐量很低但是CPU使用率却很高，很可能是低效率代码导致的。这种情况下，你应该使用分析工具定位代码中性能的瓶颈。可使用的工具有：**JVisualVM**、Eclipse **TPTP**或者**JProbe**。

## 2.12 调优方法

建议你使用如下方法对程序进行调优。

首先，检查性能调优是否必要。测量性能不是一件简单的工作，你也不能保证每次都获得满意的结果。因此如果程序已经满足预期性能需求，不必在调优上增加额外的投入了。

问题只出在一个地方，你要做的就是去解决掉它。二八定律（[Pareto principle](http://en.wikipedia.org/wiki/Pareto_principle)）对性能调优同样适用。这不是说某个模块的低性能一定只源于一个问题，而是强调我们应该在调优时把注意力放在影响最大的那个问题上。在处理好了最重要的之后，你才应该去解决剩下其他的。也就是建议一次只对一个问题进行修复。

另外需要考虑到气球效应（[Balloon effect](http://en.wikipedia.org/wiki/Balloon_effect)），有得必有失。你可以通过使用缓存来提高响应能力，但是当缓存逐渐增大，执行一次Full GC的时间也会更长。一般而言，如果你希望内存使用率比较低，那么吞吐量和响应能力可能都会恶化。因此，要知道什么对自己程序来说最重要的，而哪些又是次要的。

到此为止，你应该已经了解了如何对Java程序进行性能调优。为了介绍性能测定的具体过程，我不得不省略其中一些细节，不过我认为这些也足够应对大多数Java Web服务端程序了。



# 3. JVM 优化经验总结

## 3.1 开始之前

Java 虚拟机有自己完善的硬件架构, 如处理器、堆栈、寄存器等，还具有相应的指令系统。JVM 屏蔽了与具体操作系统平台相关的信息，使得 Java 程序只需生成在 Java 虚拟机上运行的目标代码 (字节码), 就可以在多种平台上不加修改地运行。Java 虚拟机在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行。

注意：本文仅针对 JDK7、HotSPOT Java 虚拟机，对于 JDK8 引入的 JVM 新特性及其他 Java 虚拟机，本文不予关注。

我们以一个例子开始这篇文章。假设你是一个普通的 Java 对象，你出生在 Eden 区，在 Eden 区有许多和你差不多的小兄弟、小姐妹，可以把 Eden 区当成幼儿园，在这个幼儿园里大家玩了很长时间。Eden 区不能无休止地放你们在里面，所以当年纪稍大，你就要被送到学校去上学，这里假设从小学到高中都称为 Survivor 区。开始的时候你在 Survivor 区里面划分出来的的“From”区，读到高年级了，就进了 Survivor 区的“To”区，中间由于学习成绩不稳定，还经常来回折腾。直到你 18 岁的时候，高中毕业了，该去社会上闯闯了。于是你就去了年老代，年老代里面人也很多。在年老代里，你生活了 20 年 (每次 GC 加一岁)，最后寿终正寝，被 GC 回收。有一点没有提，你在年老代遇到了一个同学，他的名字叫爱德华 (慕光之城里的帅哥吸血鬼)，他以及他的家族永远不会死，那么他们就生活在永生代。

之前的文章[《JVM 垃圾回收器工作原理及使用实例介绍》](https://www.ibm.com/developerworks/cn/java/j-lo-JVMGarbageCollection/)中已经介绍过年轻代、年老代、永生代，本文主要讲讲如何运用这些区域，为系统性能提供更好的帮助。本文不再重复这些概念，直接进入主题。

## 3.2 如何将新对象预留在年轻代

众所周知，由于 Full GC 的成本远远高于 Minor GC，因此某些情况下需要尽可能将对象分配在年轻代，这在很多情况下是一个明智的选择。虽然在大部分情况下，JVM 会尝试在 Eden 区分配对象，但是由于空间紧张等问题，很可能不得不将部分年轻对象提前向年老代压缩。因此，在 JVM 参数调优时可以为应用程序分配一个合理的年轻代空间，以最大限度避免新对象直接进入年老代的情况发生。清单 1 所示代码尝试分配 4MB 内存空间，观察一下它的内存使用情况。

**清单 1. 相同大小内存分配**

```
`public class PutInEden {`` ``public static void main(String[] args){`` ``byte[] b1,b2,b3,b4;//定义变量`` ``b1=new byte[1024*1024];//分配 1MB 堆空间，考察堆空间的使用情况`` ``b2=new byte[1024*1024];`` ``b3=new byte[1024*1024];`` ``b4=new byte[1024*1024];`` ``}``}`
```

使用 JVM 参数-XX:+PrintGCDetails -Xmx20M -Xms20M 运行清单 1 所示代码，输出如清单 2 所示。

**清单 2. 清单 1 运行输出**

```shell
`[GC [DefNew: 5504K->640K(6144K), 0.0114236 secs] 5504K->5352K(19840K), ``   ``0.0114595 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] ``[GC [DefNew: 6144K->640K(6144K), 0.0131261 secs] 10856K->10782K(19840K),``0.0131612 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] ``[GC [DefNew: 6144K->6144K(6144K), 0.0000170 secs][Tenured: 10142K->13695K(13696K),``0.1069249 secs] 16286K->15966K(19840K), [Perm : 376K->376K(12288K)],``0.1070058 secs] [Times: user=0.03 sys=0.00, real=0.11 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0302067 secs] 19839K->19595K(19840K), ``[Perm : 376K->376K(12288K)], 0.0302635 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0311986 secs] 19839K->19839K(19840K), ``[Perm : 376K->376K(12288K)], 0.0312515 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0358821 secs] 19839K->19825K(19840K), ``[Perm : 376K->371K(12288K)], 0.0359315 secs] [Times: user=0.05 sys=0.00, real=0.05 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0283080 secs] 19839K->19839K(19840K),``[Perm : 371K->371K(12288K)], 0.0283723 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0284469 secs] 19839K->19839K(19840K),``[Perm : 371K->371K(12288K)], 0.0284990 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0283005 secs] 19839K->19839K(19840K),``[Perm : 371K->371K(12288K)], 0.0283475 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0287757 secs] 19839K->19839K(19840K),``[Perm : 371K->371K(12288K)], 0.0288294 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0288219 secs] 19839K->19839K(19840K), ``[Perm : 371K->371K(12288K)], 0.0288709 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0293071 secs] 19839K->19839K(19840K),``[Perm : 371K->371K(12288K)], 0.0293607 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 13695K->13695K(13696K), 0.0356141 secs] 19839K->19838K(19840K),``[Perm : 371K->371K(12288K)], 0.0356654 secs] [Times: user=0.01 sys=0.00, real=0.03 secs] ``Heap`` ``def new generation total 6144K, used 6143K [0x35c10000, 0x362b0000, 0x362b0000)`` ``eden space 5504K, 100% used [0x35c10000, 0x36170000, 0x36170000)`` ``from space 640K, 99% used [0x36170000, 0x3620fc80, 0x36210000)`` ``to space 640K, 0% used [0x36210000, 0x36210000, 0x362b0000)`` ``tenured generation total 13696K, used 13695K [0x362b0000, 0x37010000, 0x37010000)`` ``the space 13696K, 99% used [0x362b0000, 0x3700fff8, 0x37010000, 0x37010000)`` ``compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706cd20, 0x3706ce00, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)`` ``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

清单 2 所示的日志输出显示年轻代 Eden 的大小有 5MB 左右。分配足够大的年轻代空间，使用 JVM 参数-XX:+PrintGCDetails -Xmx20M -Xms20M-Xmn6M 运行清单 1 所示代码，输出如清单 3 所示。

**清单 3. 增大 Eden 大小后清单 1 运行输出**

```shell
`[GC [DefNew: 4992K->576K(5568K), 0.0116036 secs] 4992K->4829K(19904K), `` ``0.0116439 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] ``[GC [DefNew: 5568K->576K(5568K), 0.0130929 secs] 9821K->9653K(19904K), ``0.0131336 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] ``[GC [DefNew: 5568K->575K(5568K), 0.0154148 secs] 14645K->14500K(19904K),``0.0154531 secs] [Times: user=0.00 sys=0.01, real=0.01 secs] ``[GC [DefNew: 5567K->5567K(5568K), 0.0000197 secs][Tenured: 13924K->14335K(14336K),``0.0330724 secs] 19492K->19265K(19904K), [Perm : 376K->376K(12288K)],``0.0331624 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 14335K->14335K(14336K), 0.0292459 secs] 19903K->19902K(19904K),``[Perm : 376K->376K(12288K)], 0.0293000 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 14335K->14335K(14336K), 0.0278675 secs] 19903K->19903K(19904K),``[Perm : 376K->376K(12288K)], 0.0279215 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured: 14335K->14335K(14336K), 0.0348408 secs] 19903K->19889K(19904K),``[Perm : 376K->371K(12288K)], 0.0348945 secs] [Times: user=0.05 sys=0.00, real=0.05 secs] ``[Full GC [Tenured: 14335K->14335K(14336K), 0.0299813 secs] 19903K->19903K(19904K),``[Perm : 371K->371K(12288K)], 0.0300349 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] ``[Full GC [Tenured: 14335K->14335K(14336K), 0.0298178 secs] 19903K->19903K(19904K),``[Perm : 371K->371K(12288K)], 0.0298688 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``Exception in thread "main" java.lang.OutOfMemoryError: Java heap space[Full GC [Tenured: ``14335K->14335K(14336K), 0.0294953 secs] 19903K->19903K(19904K),``[Perm : 371K->371K(12288K)], 0.0295474 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenured``: 14335K->14335K(14336K), 0.0287742 secs] 19903K->19903K(19904K), ``[Perm : 371K->371K(12288K)], 0.0288239 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``[Full GC [Tenuredat GCTimeTest.main(GCTimeTest.java:16)``: 14335K->14335K(14336K), 0.0287102 secs] 19903K->19903K(19904K),``[Perm : 371K->371K(12288K)], 0.0287627 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] ``Heap`` ``def new generation total 5568K, used 5567K [0x35c10000, 0x36210000, 0x36210000)`` ``eden space 4992K, 100% used [0x35c10000, 0x360f0000, 0x360f0000)`` ``from space 576K, 99% used [0x36180000, 0x3620ffe8, 0x36210000)`` ``to space 576K, 0% used [0x360f0000, 0x360f0000, 0x36180000)`` ``tenured generation total 14336K, used 14335K [0x36210000, 0x37010000, 0x37010000)`` ``the space 14336K, 99% used [0x36210000, 0x3700ffd8, 0x37010000, 0x37010000)`` ``compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706ce28, 0x3706d000, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)`` ``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

通过清单 2 和清单 3 对比，可以发现通过设置一个较大的年轻代预留新对象，设置合理的 Survivor 区并且提供 Survivor 区的使用率，可以将年轻对象保存在年轻代。一般来说，Survivor 区的空间不够，或者占用量达到 50%时，就会使对象进入年老代 (不管它的年龄有多大)。清单 4 创建了 3 个对象，分别分配一定的内存空间。

**清单 4. 不同大小内存分配**

```
`public class PutInEden2 {`` ``public static void main(String[] args){`` ``byte[] b1,b2,b3;`` ``b1=new byte[1024*512];//分配 0.5MB 堆空间`` ``b2=new byte[1024*1024*4];//分配 4MB 堆空间`` ``b3=new byte[1024*1024*4];`` ``b3=null; //使 b3 可以被回收`` ``b3=new byte[1024*1024*4];//分配 4MB 堆空间`` ``}``}`
```

使用参数-XX:+PrintGCDetails -Xmx1000M -Xms500M -Xmn100M -XX:SurvivorRatio=8 运行清单 4 所示代码，输出如清单 5 所示。

**清单 5. 清单 4 运行输出**

```
`Heap`` ``def new generation total 92160K, used 11878K [0x0f010000, 0x15410000, 0x15410000)`` ``eden space 81920K, 2% used [0x0f010000, 0x0f1a9a20, 0x14010000)`` ``from space 10240K, 99% used [0x14a10000, 0x1540fff8, 0x15410000)`` ``to space 10240K, 0% used [0x14010000, 0x14010000, 0x14a10000)`` ``tenured generation total 409600K, used 86434K [0x15410000, 0x2e410000, 0x4d810000)`` ``the space 409600K, 21% used [0x15410000, 0x1a878b18, 0x1a878c00, 0x2e410000)`` ``compacting perm gen total 12288K, used 2062K [0x4d810000, 0x4e410000, 0x51810000)`` ``the space 12288K, 16% used [0x4d810000, 0x4da13b18, 0x4da13c00, 0x4e410000)``No shared spaces configured.`
```

清单 5 输出的日志显示，年轻代分配了 8M，年老代也分配了 8M。我们可以尝试加上-XX:TargetSurvivorRatio=90 参数，这样可以提高 from 区的利用率，使 from 区使用到 90%时，再将对象送入年老代，运行清单 4 代码，输出如清单 6 所示。

**清单 6. 修改运行参数后清单 4 输出**

```
`Heap`` ``def new generation total 9216K, used 9215K [0x35c10000, 0x36610000, 0x36610000)`` ``eden space 8192K, 100% used [0x35c10000, 0x36410000, 0x36410000)`` ``from space 1024K, 99% used [0x36510000, 0x3660fc50, 0x36610000)`` ``to space 1024K, 0% used [0x36410000, 0x36410000, 0x36510000)`` ``tenured generation total 10240K, used 10239K [0x36610000, 0x37010000, 0x37010000)`` ``the space 10240K, 99% used [0x36610000, 0x3700ff70, 0x37010000, 0x37010000)`` ``compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706cd90, 0x3706ce00, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)`` ``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

如果将 SurvivorRatio 设置为 2，将 b1 对象预存在年轻代。输出如清单 7 所示。

**清单 7. 再次修改运行参数后清单 4 输出**

```
`Heap`` ``def new generation total 7680K, used 7679K [0x35c10000, 0x36610000, 0x36610000)`` ``eden space 5120K, 100% used [0x35c10000, 0x36110000, 0x36110000)`` ``from space 2560K, 99% used [0x36110000, 0x3638fff0, 0x36390000)`` ``to space 2560K, 0% used [0x36390000, 0x36390000, 0x36610000)`` ``tenured generation total 10240K, used 10239K [0x36610000, 0x37010000, 0x37010000)`` ``the space 10240K, 99% used [0x36610000, 0x3700fff0, 0x37010000, 0x37010000)`` ``compacting perm gen total 12288K, used 371K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706ce28, 0x3706d000, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

## 3.3 如何让大对象进入年老代

我们在大部分情况下都会选择将对象分配在年轻代。但是，对于占用内存较多的大对象而言，它的选择可能就不是这样的。因为大对象出现在年轻代很可能扰乱年轻代 GC，并破坏年轻代原有的对象结构。因为尝试在年轻代分配大对象，很可能导致空间不足，为了有足够的空间容纳大对象，JVM 不得不将年轻代中的年轻对象挪到年老代。因为大对象占用空间多，所以可能需要移动大量小的年轻对象进入年老代，这对 GC 相当不利。基于以上原因，可以将大对象直接分配到年老代，保持年轻代对象结构的完整性，这样可以提高 GC 的效率。如果一个大对象同时又是一个短命的对象，假设这种情况出现很频繁，那对于 GC 来说会是一场灾难。原本应该用于存放永久对象的年老代，被短命的对象塞满，这也意味着对堆空间进行了洗牌，扰乱了分代内存回收的基本思路。因此，在软件开发过程中，应该尽可能避免使用短命的大对象。可以使用参数-XX:PetenureSizeThreshold 设置大对象直接进入年老代的阈值。当对象的大小超过这个值时，将直接在年老代分配。参数-XX:PetenureSizeThreshold 只对串行收集器和年轻代并行收集器有效，并行回收收集器不识别这个参数。

**清单 8. 创建一个大对象**

```
`public class BigObj2Old {`` ``public static void main(String[] args){`` ``byte[] b;`` ``b = new byte[1024*1024];//分配一个 1MB 的对象`` ``}``}`
```

使用 JVM 参数-XX:+PrintGCDetails –Xmx20M –Xms20MB 运行，可以得到清单 9 所示日志输出。

**清单 9. 清单 8 运行输出**

```
`Heap`` ``def new generation total 6144K, used 1378K [0x35c10000, 0x362b0000, 0x362b0000)`` ``eden space 5504K, 25% used [0x35c10000, 0x35d689e8, 0x36170000)`` ``from space 640K, 0% used [0x36170000, 0x36170000, 0x36210000)`` ``to space 640K, 0% used [0x36210000, 0x36210000, 0x362b0000)`` ``tenured generation total 13696K, used 0K [0x362b0000, 0x37010000, 0x37010000)`` ``the space 13696K, 0% used [0x362b0000, 0x362b0000, 0x362b0200, 0x37010000)`` ``compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706dac8, 0x3706dc00, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)`` ``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

可以看到该对象被分配在了年轻代，占用了 25%的空间。如果需要将 1MB 以上的对象直接在年老代分配，设置-XX:PetenureSizeThreshold=1000000，程序运行后输出如清单 10 所示。

**清单 10. 修改运行参数后清单 8 输出**

```
`Heap`` ``def new generation total 6144K, used 354K [0x35c10000, 0x362b0000, 0x362b0000)`` ``eden space 5504K, 6% used [0x35c10000, 0x35c689d8, 0x36170000)`` ``from space 640K, 0% used [0x36170000, 0x36170000, 0x36210000)`` ``to space 640K, 0% used [0x36210000, 0x36210000, 0x362b0000)`` ``tenured generation total 13696K, used 1024K [0x362b0000, 0x37010000, 0x37010000)`` ``the space 13696K, 7% used [0x362b0000, 0x363b0010, 0x363b0200, 0x37010000)`` ``compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706dac8, 0x3706dc00, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)`` ``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

清单 10 里面可以看到当满 1MB 时进入到了年老代。

## 3.4 如何设置对象进入年老代的年龄

堆中的每一个对象都有自己的年龄。一般情况下，年轻对象存放在年轻代，年老对象存放在年老代。为了做到这点，虚拟机为每个对象都维护一个年龄。如果对象在 Eden 区，经过一次 GC 后依然存活，则被移动到 Survivor 区中，对象年龄加 1。以后，如果对象每经过一次 GC 依然存活，则年龄再加 1。当对象年龄达到阈值时，就移入年老代，成为老年对象。这个阈值的最大值可以通过参数-XX:MaxTenuringThreshold 来设置，默认值是 15。虽然-XX:MaxTenuringThreshold 的值可能是 15 或者更大，但这不意味着新对象非要达到这个年龄才能进入年老代。事实上，对象实际进入年老代的年龄是虚拟机在运行时根据内存使用情况动态计算的，这个参数指定的是阈值年龄的最大值。即，实际晋升年老代年龄等于动态计算所得的年龄与-XX:MaxTenuringThreshold 中较小的那个。清单 11 所示代码为 3 个对象申请了若干内存。

**清单 11. 申请内存**

```
`public class MaxTenuringThreshold {`` ``public static void main(String args[]){`` ``byte[] b1,b2,b3;`` ``b1 = new byte[1024*512];`` ``b2 = new byte[1024*1024*2];`` ``b3 = new byte[1024*1024*4];`` ``b3 = null;`` ``b3 = new byte[1024*1024*4];`` ``}``}`
```

参数设置为：-XX:+PrintGCDetails -Xmx20M -Xms20M -Xmn10M -XX:SurvivorRatio=2

运行清单 11 所示代码，输出如清单 12 所示。

**清单 12. 清单 11 运行输出**

```
`[GC [DefNew: 2986K->690K(7680K), 0.0246816 secs] 2986K->2738K(17920K),`` ``0.0247226 secs] [Times: user=0.00 sys=0.02, real=0.03 secs] ``[GC [DefNew: 4786K->690K(7680K), 0.0016073 secs] 6834K->2738K(17920K), ``0.0016436 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ``Heap`` ``def new generation total 7680K, used 4888K [0x35c10000, 0x36610000, 0x36610000)`` ``eden space 5120K, 82% used [0x35c10000, 0x36029a18, 0x36110000)`` ``from space 2560K, 26% used [0x36110000, 0x361bc950, 0x36390000)`` ``to space 2560K, 0% used [0x36390000, 0x36390000, 0x36610000)`` ``tenured generation total 10240K, used 2048K [0x36610000, 0x37010000, 0x37010000)`` ``the space 10240K, 20% used [0x36610000, 0x36810010, 0x36810200, 0x37010000)`` ``compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706db50, 0x3706dc00, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)`` ``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

更改参数为-XX:+PrintGCDetails -Xmx20M -Xms20M -Xmn10M -XX:SurvivorRatio=2 -XX:MaxTenuringThreshold=1，运行清单 11 所示代码，输出如清单 13 所示。

**清单 13. 修改运行参数后清单 11 输出**

```
`[GC [DefNew: 2986K->690K(7680K), 0.0047778 secs] 2986K->2738K(17920K),`` ``0.0048161 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ``[GC [DefNew: 4888K->0K(7680K), 0.0016271 secs] 6936K->2738K(17920K),``0.0016630 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ``Heap`` ``def new generation total 7680K, used 4198K [0x35c10000, 0x36610000, 0x36610000)`` ``eden space 5120K, 82% used [0x35c10000, 0x36029a18, 0x36110000)`` ``from space 2560K, 0% used [0x36110000, 0x36110088, 0x36390000)`` ``to space 2560K, 0% used [0x36390000, 0x36390000, 0x36610000)`` ``tenured generation total 10240K, used 2738K [0x36610000, 0x37010000, 0x37010000)`` ``the space 10240K, 26% used [0x36610000, 0x368bc890, 0x368bca00, 0x37010000)`` ``compacting perm gen total 12288K, used 374K [0x37010000, 0x37c10000, 0x3b010000)`` ``the space 12288K, 3% used [0x37010000, 0x3706db50, 0x3706dc00, 0x37c10000)`` ``ro space 10240K, 51% used [0x3b010000, 0x3b543000, 0x3b543000, 0x3ba10000)`` ``rw space 12288K, 55% used [0x3ba10000, 0x3c0ae4f8, 0x3c0ae600, 0x3c610000)`
```

清单 13 所示，第一次运行时 b1 对象在程序结束后依然保存在年轻代。第二次运行前，我们减小了对象晋升年老代的年龄，设置为 1。即，所有经过一次 GC 的对象都可以直接进入年老代。程序运行后，可以发现 b1 对象已经被分配到年老代。如果希望对象尽可能长时间地停留在年轻代，可以设置一个较大的阈值。

## 3.5 稳定的 Java 堆 VS 动荡的 Java 堆

一般来说，稳定的堆大小对垃圾回收是有利的。获得一个稳定的堆大小的方法是使-Xms 和-Xmx 的大小一致，即最大堆和最小堆 (初始堆) 一样。如果这样设置，系统在运行时堆大小理论上是恒定的，稳定的堆空间可以减少 GC 的次数。因此，很多服务端应用都会将最大堆和最小堆设置为相同的数值。但是，一个不稳定的堆并非毫无用处。稳定的堆大小虽然可以减少 GC 次数，但同时也增加了每次 GC 的时间。让堆大小在一个区间中震荡，在系统不需要使用大内存时，压缩堆空间，使 GC 应对一个较小的堆，可以加快单次 GC 的速度。基于这样的考虑，JVM 还提供了两个参数用于压缩和扩展堆空间。

-XX:MinHeapFreeRatio 参数用来设置堆空间最小空闲比例，默认值是 40。当堆空间的空闲内存小于这个数值时，JVM 便会扩展堆空间。

-XX:MaxHeapFreeRatio 参数用来设置堆空间最大空闲比例，默认值是 70。当堆空间的空闲内存大于这个数值时，便会压缩堆空间，得到一个较小的堆。

当-Xmx 和-Xms 相等时，-XX:MinHeapFreeRatio 和-XX:MaxHeapFreeRatio 两个参数无效。

**清单 14. 堆大小设置**

```
`import java.util.Vector;` `public class HeapSize {`` ``public static void main(String args[]) throws InterruptedException{`` ``Vector v = new Vector();`` ``while(true){`` ``byte[] b = new byte[1024*1024];`` ``v.add(b);`` ``if(v.size() == 10){`` ``v = new Vector();`` ``}`` ``Thread.sleep(1);`` ``}`` ``}``}`
```

清单 14 所示代码是测试-XX:MinHeapFreeRatio 和-XX:MaxHeapFreeRatio 的作用，设置运行参数为-XX:+PrintGCDetails -Xms10M -Xmx40M -XX:MinHeapFreeRatio=40 -XX:MaxHeapFreeRatio=50 时，输出如清单 15 所示。

**清单 15. 修改运行参数后清单 14 输出**

```
`[GC [DefNew: 2418K->178K(3072K), 0.0034827 secs] 2418K->2226K(9920K),`` ``0.0035249 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] ``[GC [DefNew: 2312K->0K(3072K), 0.0028263 secs] 4360K->4274K(9920K), ``0.0029905 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] ``[GC [DefNew: 2068K->0K(3072K), 0.0024363 secs] 6342K->6322K(9920K),``0.0024836 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] ``[GC [DefNew: 2061K->0K(3072K), 0.0017376 secs][Tenured: 8370K->8370K(8904K),``0.1392692 secs] 8384K->8370K(11976K), [Perm : 374K->374K(12288K)],``0.1411363 secs] [Times: user=0.00 sys=0.02, real=0.16 secs] ``[GC [DefNew: 5138K->0K(6336K), 0.0038237 secs] 13508K->13490K(20288K),``0.0038632 secs] [Times: user=0.00 sys=0.00, real=0.03 secs]`
```

改用参数：-XX:+PrintGCDetails -Xms40M -Xmx40M -XX:MinHeapFreeRatio=40 -XX:MaxHeapFreeRatio=50，运行输出如清单 16 所示。

**清单 16. 再次修改运行参数后清单 14 输出**

```
`[GC [DefNew: 10678K->178K(12288K), 0.0019448 secs] 10678K->178K(39616K), `` ``0.0019851 secs] [Times: user=0.00 sys=0.00, real=0.03 secs] ``[GC [DefNew: 10751K->178K(12288K), 0.0010295 secs] 10751K->178K(39616K),``0.0010697 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] ``[GC [DefNew: 10493K->178K(12288K), 0.0008301 secs] 10493K->178K(39616K),``0.0008672 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] ``[GC [DefNew: 10467K->178K(12288K), 0.0008522 secs] 10467K->178K(39616K),``0.0008905 secs] [Times: user=0.00 sys=0.00, real=0.02 secs] ``[GC [DefNew: 10450K->178K(12288K), 0.0008964 secs] 10450K->178K(39616K),``0.0009339 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] ``[GC [DefNew: 10439K->178K(12288K), 0.0009876 secs] 10439K->178K(39616K),``0.0010279 secs] [Times: user=0.00 sys=0.00, real=0.02 secs]`
```

从清单 16 可以看出，此时堆空间的垃圾回收稳定在一个固定的范围。在一个稳定的堆中，堆空间大小始终不变，每次 GC 时，都要应对一个 40MB 的空间。因此，虽然 GC 次数减小了，但是单次 GC 速度不如一个震荡的堆。

## 3.6 增大吞吐量提升系统性能

吞吐量优先的方案将会尽可能减少系统执行垃圾回收的总时间，故可以考虑关注系统吞吐量的并行回收收集器。在拥有高性能的计算机上，进行吞吐量优先优化，可以使用参数：

```
`java –Xmx3800m –Xms3800m –Xmn2G –Xss128k –XX:+UseParallelGC ``   ``–XX:ParallelGC-Threads=20 –XX:+UseParallelOldGC`
```

–Xmx380m –Xms3800m：设置 Java 堆的最大值和初始值。一般情况下，为了避免堆内存的频繁震荡，导致系统性能下降，我们的做法是设置最大堆等于最小堆。假设这里把最小堆减少为最大堆的一半，即 1900m，那么 JVM 会尽可能在 1900MB 堆空间中运行，如果这样，发生 GC 的可能性就会比较高；

-Xss128k：减少线程栈的大小，这样可以使剩余的系统内存支持更多的线程；

-Xmn2g：设置年轻代区域大小为 2GB；

–XX:+UseParallelGC：年轻代使用并行垃圾回收收集器。这是一个关注吞吐量的收集器，可以尽可能地减少 GC 时间。

–XX:ParallelGC-Threads：设置用于垃圾回收的线程数，通常情况下，可以设置和 CPU 数量相等。但在 CPU 数量比较多的情况下，设置相对较小的数值也是合理的；

–XX:+UseParallelOldGC：设置年老代使用并行回收收集器。

## 3.7 尝试使用大的内存分页

CPU 是通过寻址来访问内存的。32 位 CPU 的寻址宽度是 0~0xFFFFFFFF ，计算后得到的大小是 4G，也就是说可支持的物理内存最大是 4G。但在实践过程中，碰到了这样的问题，程序需要使用 4G 内存，而可用物理内存小于 4G，导致程序不得不降低内存占用。为了解决此类问题，现代 CPU 引入了 MMU（Memory Management Unit 内存管理单元）。MMU 的核心思想是利用虚拟地址替代物理地址，即 CPU 寻址时使用虚址，由 MMU 负责将虚址映射为物理地址。MMU 的引入，解决了对物理内存的限制，对程序来说，就像自己在使用 4G 内存一样。内存分页 (Paging) 是在使用 MMU 的基础上，提出的一种内存管理机制。它将虚拟地址和物理地址按固定大小（4K）分割成页 (page) 和页帧 (page frame)，并保证页与页帧的大小相同。这种机制，从数据结构上，保证了访问内存的高效，并使 OS 能支持非连续性的内存分配。在程序内存不够用时，还可以将不常用的物理内存页转移到其他存储设备上，比如磁盘，这就是大家耳熟能详的虚拟内存。

在 Solaris 系统中，JVM 可以支持 Large Page Size 的使用。使用大的内存分页可以增强 CPU 的内存寻址能力，从而提升系统的性能。

```
`java –Xmx2506m –Xms2506m –Xmn1536m –Xss128k –XX:++UseParallelGC`` ``–XX:ParallelGCThreads=20 –XX:+UseParallelOldGC –XX:+LargePageSizeInBytes=256m`
```

–XX:+LargePageSizeInBytes：设置大页的大小。

过大的内存分页会导致 JVM 在计算 Heap 内部分区（perm, new, old）内存占用比例时，会出现超出正常值的划分，最坏情况下某个区会多占用一个页的大小。

## 3.8 使用非占有的垃圾回收器

为降低应用软件的垃圾回收时的停顿，首先考虑的是使用关注系统停顿的 CMS 回收器，其次，为了减少 Full GC 次数，应尽可能将对象预留在年轻代，因为年轻代 Minor GC 的成本远远小于年老代的 Full GC。

```
`java –Xmx3550m –Xms3550m –Xmn2g –Xss128k –XX:ParallelGCThreads=20`` ``–XX:+UseConcMarkSweepGC –XX:+UseParNewGC –XX:+SurvivorRatio=8 –XX:TargetSurvivorRatio=90`` ``–XX:MaxTenuringThreshold=31`
```

–XX:ParallelGCThreads=20：设置 20 个线程进行垃圾回收；

–XX:+UseParNewGC：年轻代使用并行回收器；

–XX:+UseConcMarkSweepGC：年老代使用 CMS 收集器降低停顿；

–XX:+SurvivorRatio：设置 Eden 区和 Survivor 区的比例为 8:1。稍大的 Survivor 空间可以提高在年轻代回收生命周期较短的对象的可能性，如果 Survivor 不够大，一些短命的对象可能直接进入年老代，这对系统来说是不利的。

–XX:TargetSurvivorRatio=90：设置 Survivor 区的可使用率。这里设置为 90%，则允许 90%的 Survivor 空间被使用。默认值是 50%。故该设置提高了 Survivor 区的使用率。当存放的对象超过这个百分比，则对象会向年老代压缩。因此，这个选项更有助于将对象留在年轻代。

–XX:MaxTenuringThreshold：设置年轻对象晋升到年老代的年龄。默认值是 15 次，即对象经过 15 次 Minor GC 依然存活，则进入年老代。这里设置为 31，目的是让对象尽可能地保存在年轻代区域。

## 3.9 结束语

通过本文的学习，读者了解了如何将新对象预留在年轻代、如何让大对象进入年老代、如何设置对象进入年老代的年龄、稳定的 Java 堆 VS 动荡的 Java 堆、增大吞吐量提升系统性能、尝试使用大的内存分页、使用非占有的垃圾回收器等主题，通过实例及对应输出解释的形式让读者对于 JVM 优化有一个初步认识。如其他文章相同的观点，没有哪一条优化是固定不变的，读者需要自己判断、实践后才能找到正确的道路。



















































































